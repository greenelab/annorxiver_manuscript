## Results

### Comparing bioRxiv to other corpora

#### bioRxiv Metadata Statistics

The preprint landscape is rapidly changing, and the number of bioRxiv preprints in our data download (71,118) was nearly double that of a recent study that reported on a snapshot with 37,648 preprints [@doi:10.7554/eLife.45133].
Because the rate of change is rapid, we first analyzed category data and compared our results with previous findings.
As in previous reports [@doi:10.7554/eLife.45133], neuroscience remains the most common category of preprints, followed by bioinformatics (Supplemental Figure {@fig:biorxiv_categories}).
Microbiology, which was fifth in the most recent report [@doi:10.7554/eLife.45133], has now surpassed evolutionary biology and genomics to move into third.
When authors upload their preprints, they select from three result category types: new results, confirmatory results, or contradictory results.
We found that nearly all preprints (97.5%) were categorized as new results, consistent with reports on a smaller set [@doi:10.1001/jama.2017.21168].
The results taken together suggest that while bioRxiv has experienced dramatic growth, how it is being used appears to have remained consistent in recent years.

#### Global analysis reveals similarities and differences between bioRxiv and PMC

| Metric                | bioRxiv     | PMC           | NYTAC         |
|-----------------------|-------------|---------------|---------------|
| document count             | 71,118      | 1,977,647     | 1,855,658     |
| sentence count             | 22,195,739  | 480,489,811   | 72,171,037    |
| token count                | 420,969,930 | 8,597,101,167 | 1,218,673,384 |
| stopword count            | 158,429,441 | 3,153,077,263 | 559,391,073   |
| avg. document length        | 312.10      | 242.96        | 38.89         |
| avg. sentence length        | 22.71       | 21.46         | 19.89         |
| negatives                  | 1,148,382   | 24,928,801    | 7,272,401     |
| coordinating conjunctions  | 14,295,736  | 307,082,313   | 38,730,053    |
| coordinating conjunctions% | 3.40%       | 3.57%         | 3.18%         |
| pronouns                   | 4,604,432   | 74,994,125    | 46,712,553    |
| pronouns%                  | 1.09%        | 0.87%         | 3.83%         |
| passives                   | 15,012,441  | 342,407,363   | 19,472,053    |
| passive%                   | 3.57%       | 3.98%         | 1.60%         |

Table: Summary statistics for the bioRxiv, PMC, and NYTAC corpora. {#tbl:corpora_stats}

![
**A.** The Kullback–Leibler divergence measures the extent to which the distributions, not specific tokens, differ from each other.
The token distribution of bioRxiv and PMC corpora is more similar than these biomedical corpora are to the NYTAC one.
**B.** The significant differences in token frequencies for the corpora appear to be driven by the fields with the highest uptake of bioRxiv, as terms from neuroscience and genomics are relatively more abundant in bioRxiv.
We plotted the 95% confidence interval for each reported token.
**C.** Of the tokens that differ between bioRxiv and PMC, the most abundant in bioRxiv are "et" and "al" while the most abundant in PMC is "study."
**D.** The significant differences in token frequencies for preprints and their corresponding published version often appear to be associated with typesetting and supplementary or additional materials.
We plotted the 95% confidence interval for each reported token.
**E.** The tokens with the largest absolute differences in abundance appear to be stylistic.
](https://raw.githubusercontent.com/danich1/annorxiver/77e9d6437069bafec7f0291b9a6c09ad50374b58/figure_generation/output/figure_one_panels.svg){#fig:corpora_comparison_panels width="100%"}

Documents within bioRxiv were slightly longer than those within PMCOA, but both were much longer than those from the control (NYTAC) (Table {@tbl:corpora_stats}).
The average sentence length, the fraction of pronouns, and the use of the passive voice were all more similar between bioRxiv and PMC than they were to NYTAC(Table {@tbl:corpora_stats}).
The Kullback–Leibler (KL) divergence of term frequency distributions between bioRxiv and PMCOA were low, especially among the top few hundred tokens (Figure {@fig:corpora_comparison_panels}A).
As more tokens were incorporated, the KL divergence started to increase but remained much lower than the biomedical corpora compared against NYTAC.
These findings support our notion that bioRxiv is linguistically similar to the PMCOA repository.

Terms like "neurons", "genome", and "genetic", which are common in genomics and neuroscience, were more common in bioRxiv than PMCOA while others associated with clinical research, such as "clinical" "patients" and "treatment" were more common in PMCOA (Figure {@fig:corpora_comparison_panels}B and {@fig:corpora_comparison_panels}C).
When controlling for the differences in the body of documents to identify textual changes associated with the publication process, we found that tokens such as "et" "al" were enriched for bioRxiv while "$\pm$", "–" were enriched for PMCOA (Figure {@fig:corpora_comparison_panels}D and {@fig:corpora_comparison_panels}E).
Furthermore, we found that specific changes appeared to be related to journal styles: "figure" was more common in bioRxiv while "fig" was relatively more common in PMCOA.
Other changes appeared to be associated with an increasing reference to content external to the manuscript itself: the tokens "supplementary", "additional" and "file" were all more common in PMCOA than bioRxiv, suggesting that journals are not simply replacing one token with another but that there are more mentions of such content after peer review.

These results taken together suggest that the structure of the text within preprints on bioRxiv are similar to published articles within PMCOA.
The differences in uptake across fields are supported by differences in authors' categorization of their articles and by the text within the articles themselves.
At the level of individual manuscripts, the terms that change the most appear to be associated with typesetting, journal style, and an increasing reliance on additional materials after peer review.

### Document embedding similarities reveal unannotated preprint-publication pairs

![
**A.** Preprints are closer in document embedding space to their corresponding peer-reviewed publication than they are to random papers published in the same journal.
**B.** Potential preprint-publication pairs that are unannotated but within the 50th percentile of all preprint-publication pairs in the document embedding space are likely to represent true preprint-publication pairs.
We depict the fraction of true positives over the total number of pairs in each bin.
Accuracy is derived from the curation of a randomized list of 200 potential pairs (50 per quantile) performed in duplicate with a third rater used in the case of disagreement.
**C.** Most preprints are eventually published.
We show the publication rate of preprints since bioRxiv first started.
The x-axis represents months since bioRxiv started, and the y-axis represents the proportion of preprints published given the month they were posted.
The light blue line represents the publication rate previously estimated by Abdill et al. [@doi:10.7554/eLife.45133].
The dark blue line represents the updated publication rate using only CrossRef-derived annotations, while the dark green line includes annotations derived from our embedding space approach.
The horizontal lines represent the overall proportion of preprints published as of the time of the annotation snapshot.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_three_panels.svg){#fig:preprint_links_panels width="100%"}

Distances between preprints and their corresponding published versions were nearly always lower than preprints paired with a random article published in the same journal (Figure {@fig:preprint_links_panels}A).
This suggests that embedding distances can identify documents with similar textual content. 
Approximately 98% of our 200 pairs with an embedding distance in the 0-25th and 25th-50th percentile bins were scored as true matches (Figure {@fig:preprint_links_panels}B).
These two bins contained 1,542 preprint-article pairs, suggesting that many preprints may have been published but not previously connected with their published versions.
There is a particular enrichment for preprints published but unlinked within the 2017-2018 interval (Figure {@fig:preprint_links_panels}C).
We expected a higher proportion of such preprints before 2019 (many of which may not have been published yet); however, observing relatively few missed annotations before 2017 was against our expectations.
There are several possible explanations for this increasing fraction of missed annotations.
As the number of preprints posted on bioRxiv grows, it may be harder for bioRxiv to establish a link between preprints and their published counterparts simply due to the scale of the challenge.
It is possible that the set of authors participating in the preprint ecosystem is changing and that new participants may be less likely to report missed publications to bioRxiv.
Finally, as familiarity with preprinting grows, it is possible that authors are posting preprints earlier in the process and that metadata fields that bioRxiv uses to establish a link may be less stable.

### Preprints with more versions or more text changes took longer to publish

![
**A.** Author-selected categories were associated with modest differences in respect to publication half-life.
Author-selected preprint categories are shown on the y-axis, while the x-axis shows the median time-to-publish for each category.
Error bars represent 95% confidence intervals for each median measurement.
**B.** Preprints with more versions were associated with a longer time to publish.
The x-axis shows the number of versions of a preprint posted on bioRxiv.
The y-axis indicates the number of days that elapsed between the first version of a preprint posted on bioRxiv and the date at which the peer-reviewed publication appeared.
The density of observations is depicted in the violin plot with an embedded boxplot.
**C.** Preprints with more substantial text changes took longer to be published.
The x-axis shows the Euclidean distance between document representations of the first version of a preprint and its peer-reviewed form.
The y-axis shows the number of days elapsed between the first version of a preprint posted on bioRxiv and when a preprint is published.
The color bar on the right represents the density of each hexbin in this plot, where more dense regions are shown in a brighter color.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_four_panels.svg){#fig:publication_delay_panels width="100%"}

The process of peer review includes several steps, which take variable amounts of time [@doi:10.1002/nop2.51], and we sought to measure if there is a difference in publication time between author-selected categories of preprints (Figure {@fig:publication_delay_panels}A).
Of the most abundant preprint categories microbiology was the fastest to publish (140 days, (137, 145 days) [95% CI]) and genomics was the slowest (190 days, (185, 195 days) [95% CI]) (Figure {@fig:publication_delay_panels}A).
We did observe category-specific differences; however, these differences were generally modest, suggesting that the peer review process did not differ dramatically between preprint categories. 
One exception was the Scientific Communication and Education category, which took substantially longer to be peer-reviewed and published (373 days, (373, 398 days) [95% CI]).
This hints that there may be differences in the publication or peer review process or culture that apply to preprints in this category.

Examining peer review's effect on individual preprints, we found a positive correlation between preprints with multiple versions and the time elapsed until publication (Figure {@fig:publication_delay_panels}B). 
Each new version adds additional 51 days before a preprint is published.
This time duration seems broadly compatible with the amount of time it would take to receive reviews and revise a manuscript, suggesting that many authors may be updating their preprints in response to peer reviews or other external feedback.
The embedding space allows us to compare preprint and published documents to determine if the level of change that documents undergo relates to the time it takes them to be published.
Distances in this space are arbitrary and must be compared to reference distances.
We found that the average distance of two randomly selected papers from the bioinformatics category was 4.470, while the average distance of two randomly selected papers from bioRxiv was 5.343.
Preprints with large embedding space distances from their corresponding peer-reviewed publication took longer to publish (Figure {@fig:publication_delay_panels}C): each additional unit of distance corresponded to roughly forty-three additional days.

Overall, our findings support a model where preprints are reviewed multiple times or require more extensive revisions take longer to publish.


### Preprints with similar document embeddings share publication venues

We developed an online application that returns a listing of published papers and journals closest to a query preprint in document embedding space.
This application uses two k-nearest neighbor classifiers that achieved better performance than our baseline model (Supplemental Figure {@fig:knn_auc}) to identify these entities.
Users supply our app with digital object identifiers (DOIs) from bioRxiv or medRxiv, and the corresponding preprint is downloaded from the repository.
Next, the preprint's PDF is converted to text, and this text is used to construct a document embedding representation.
This representation is supplied to our classifiers to generate a listing of the ten papers and journals with the most similar representations in the embedding space (Figures {@fig:journal_rec_workflow}A,  {@fig:journal_rec_workflow}B and {@fig:journal_rec_workflow}C).
Furthermore, the user-requested preprint's location in this embedding space is then displayed on our interactive map, and users can select regions to identify the terms most associated with those regions (Figures {@fig:journal_rec_workflow}D and {@fig:journal_rec_workflow}E).
Users can also explore the terms associated with the top 50 PCs derived from the document embeddings, and those PCs vary across the document landscape.

![
The preprint-similarity-search app workflow allows users to examine where an individual preprint falls in the overall document landscape.
**A.** Starting with the home screen, users can paste in a bioRxiv or medRxiv DOI, which sends a request to bioRxiv or medRxiv.
Next, the app preprocesses the requested preprint and returns a listing of (**B**) the top ten most similar papers and (**C**) the ten closest journals.
**D.** The app also displays the location of the query preprint in PMC.
**E.** Users can select a square within the landscape to examine statistics associated with the square, including the top journals by article count in that square and the odds ratio of tokens.
](images/journal_recommender_workflow.png){#fig:journal_rec_workflow width="100%"}

### Contextualizing the Preprints in Motion Collection

![
The Preprints in Motion Collection results are similar to all preprint results, except that their time to publication was independent of the number of preprint versions and amount of linguistic change.
**A.** Tokens that differed included those associated with typesetting and those related to the nomenclature of the virus that causes COVID-19.
Error bars show 95% confidence intervals for each token.
**B.** Of the tokens that differ between Preprints in Motion and their published counterparts, the most abundant were associated with the nomenclature of the virus.
**C.** The Preprints in Motion fall across the landscape of PMCOA with respect to linguistic properties.
This square bin plot depicts the binning of all published papers within the PMCOA corpus.
High-density regions are depicted in yellow, while low-density regions are in dark blue.
Red dots represent the Preprints in Motion Collection.
**D.** The Preprints in Motion were published faster than other bioRxiv preprints, and the number of versions was not associated with an increase in time to publication.
The x-axis shows the number of versions of a preprint posted on bioRxiv.
The y-axis indicates the number of days that elapsed between the first version of a preprint posted on bioRxiv and the date at which the peer-reviewed publication appeared.
The density of observations is depicted in the violin plot with an embedded boxplot.
The red dots and red regression line represent Preprints in Motion.
**D.** The Preprints in Motion were published faster than other bioRxiv preprints, and no dependence between the amount of linguistic change and time to publish was observed.
The x-axis shows the Euclidean distance between document representations of the first version of a preprint and its peer-reviewed form.
The y-axis shows the number of days elapsed between the first version of a preprint posted on bioRxiv and when a preprint is published.
The color bar on the right represents the density of each hexbin in this plot, where more dense regions are shown in a brighter color.
The red dots and red regression line represent Preprints in Motion.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_five_panels.svg){#fig:covid_19_preprints width="100%"}

The Preprints in Motion collection included a set of preprints posted during the first four months of 2020.
We examined the extent to which preprints in this set were representative of the patterns that we identified from our analysis on all of bioRxiv.
As with all of bioRxiv, typesetting tokens changed between preprints and their paired publications.
Our token-level analysis identified certain patterns consistent with our findings across bioRxiv (Figure {@fig:covid_19_preprints}A and {@fig:covid_19_preprints}B).
However, in this set, we also observe changes likely associated with the fast-moving nature of COVID-19 research: the token "2019-ncov" became less frequently represented while "sars" and "cov-2" became more represented, likely due to a shift in nomenclature from "2019-nCoV" to "SARS-CoV-2".
The Preprints in Motion were not strongly colocalized in the linguistic landscape, suggesting that the collection covers a diverse set of research approaches (Figure {@fig:covid_19_preprints}C).
Preprints in this collection were published faster than the broader set of bioRxiv preprints (Figure {@fig:covid_19_preprints}D and {@fig:covid_19_preprints}E).
The relationship between time to publication and the number of versions (Figure {@fig:covid_19_preprints}D) and the relationship between time to publication and the amount of linguistic change (Figure {@fig:covid_19_preprints}E) were both lost in the Preprints in Motion set.
Our findings suggest that Preprints in Motion changed during publication in ways aligned with changes in the full preprint set but that peer review was accelerated in ways that broke the time dependences observed with the full bioRxiv set.
