---
author-meta:
- David N. Nicholson
- Jane Roe
bibliography:
- content/manual-references.json
date-meta: '2020-11-12'
header-includes: '<!--

  Manubot generated metadata rendered from header-includes-template.html.

  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html

  -->

  <meta name="dc.format" content="text/html" />

  <meta name="dc.title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta name="citation_title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta property="og:title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta property="twitter:title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta name="dc.date" content="2020-11-12" />

  <meta name="citation_publication_date" content="2020-11-12" />

  <meta name="dc.language" content="en-US" />

  <meta name="citation_language" content="en-US" />

  <meta name="dc.relation.ispartof" content="Manubot" />

  <meta name="dc.publisher" content="Manubot" />

  <meta name="citation_journal_title" content="Manubot" />

  <meta name="citation_technical_report_institution" content="Manubot" />

  <meta name="citation_author" content="David N. Nicholson" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />

  <meta name="citation_author_orcid" content="0000-0003-0002-5761" />

  <meta name="twitter:creator" content="@None" />

  <meta name="citation_author" content="Jane Roe" />

  <meta name="citation_author_institution" content="Department of Something, University of Whatever" />

  <meta name="citation_author_institution" content="Department of Whatever, University of Something" />

  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />

  <link rel="canonical" href="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta property="og:url" content="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta property="twitter:url" content="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta name="citation_pdf_url" content="https://greenelab.github.io/annorxiver_manuscript/manuscript.pdf" />

  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/annorxiver_manuscript/manuscript.pdf" />

  <link rel="alternate" type="text/html" href="https://greenelab.github.io/annorxiver_manuscript/v/7c4693e7f1676236b5e82fb7f81b464067ec2a70/" />

  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/annorxiver_manuscript/v/7c4693e7f1676236b5e82fb7f81b464067ec2a70/" />

  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/annorxiver_manuscript/v/7c4693e7f1676236b5e82fb7f81b464067ec2a70/manuscript.pdf" />

  <meta property="og:type" content="article" />

  <meta property="twitter:card" content="summary_large_image" />

  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />

  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />

  <meta name="theme-color" content="#ad1457" />

  <!-- end Manubot generated metadata -->'
keywords:
- biorxiv
- preprints
- pubmed central
- natural language processing
- descriptive linguistics
lang: en-US
manubot-clear-requests-cache: false
manubot-output-bibliography: output/references.json
manubot-output-citekeys: output/citations.tsv
manubot-requests-cache-path: ci/cache/requests-cache
title: Linguistic Analysis of the bioRxiv Preprint Landscape
...






<small><em>
This manuscript
([permalink](https://greenelab.github.io/annorxiver_manuscript/v/7c4693e7f1676236b5e82fb7f81b464067ec2a70/))
was automatically generated
from [greenelab/annorxiver_manuscript@7c4693e](https://github.com/greenelab/annorxiver_manuscript/tree/7c4693e7f1676236b5e82fb7f81b464067ec2a70)
on November 12, 2020.
</em></small>

## Authors



+ **David N. Nicholson**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-0002-5761](https://orcid.org/0000-0003-0002-5761)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [danich1](https://github.com/danich1)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
     · Funded by The Gordon and Betty Moore Foundation (GBMF4552); The National Institutes of Health (T32 HG000046)
  </small>

+ **Jane Roe**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [XXXX-XXXX-XXXX-XXXX](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [janeroe](https://github.com/janeroe)<br>
  <small>
     Department of Something, University of Whatever; Department of Whatever, University of Something
  </small>



## Abstract {.page_break_before}

This is the abstract. Trigger appveyor.


## Introduction

Preprints are scholarly works that are shared before they have been formally peer reviewed and published.
The practice of sharing preprints has a long history [@doi:10.1371/journal.pbio.2003995].
The longest ongoing use started with physicists in the 1990s [@doi:10.15252/embj.201695531].
Preprints were used in the life sciences community during the 1960s before publisher pressure stopped the practice [@doi:10.1371/journal.pbio.2003995].
Over the past decade preprints have made a resurgence within the life sciences community [@doi:10.1101/833400; @doi:10.7554/eLife.45133.001].
Preprints are now becoming widely accepted and used within the life sciences and other communities [@doi:10.1038/530265a; @doi:10.1016/j.bpj.2016.06.035; @doi:10.1126/science.aaf9133; @doi:10.1038/s41557-020-0477-5; @doi:10.1371/journal.pmed.1002549; @doi:10.1038/530265a; @doi:10.1371/journal.pbio.3000151; @doi:10.1099/mgen.0.000259].
Common preprint repositories include arXiv [@doi:10.1108/14666180010345564], bioRxiv [@doi:10.1101/833400] and medRxiv [@url:https://www.medrxiv.org/]; however, there are over 60 different repositories available [@url:https://scholarlykitchen.sspnet.org/2019/10/16/the-second-wave-of-preprint-servers-how-can-publishers-keep-afloat/].

The scientific community has begun to analyze the impact of preprints in the life sciences.
Preprints are being posted at an increasing rate [@doi:10.1371/journal.pbio.3000269].
Preprints are also rapidly shared on social media, routinely downloaded, and cited [@doi:10.1371/journal.pone.0047523].
Articles with matching preprint versions are cited and discussed more often than articles without them [@doi:10.1162/qss_a_00043; @doi:10.7554/eLife.52646].
Certain categories of preprints seem to be read and shared differently by both scientists and non-scientists [@doi:10.1101/2020.03.06.981589].
Across preprint servers, analyses suggest that between two-thirds to three-quarters of preprints are eventually published [@doi:10.7554/eLife.45133.001; @doi:10.1002/pra2.175].
The time required for a preprint to be published can vary from preprint to preprint; however, preprints with a single version often take less time to publish than preprints with multiple versions [@doi:10.2139/ssrn.3455146], suggesting that authors may update their preprints between submissions for peer review.

Studies of life sciences preprints have primarily focused on the metadata associated with these articles; however, their textual content remains unexamined.

We sought to understand the language landscape of preprints by performing a linguistic analysis of the _bioRxiv_ corpus.
We examined textual differences between preprints and published literature by comparing the entire corpus of preprints with articles available in the open access PubMed Central repository.
We also examined linguistic differences between preprints and their corresponding published pairs.
Examining this shift will provide a unique opportunity to ascertain parts of the peer review and publishing process and how it impacts the scholarly literature.
Neural-network derived document embeddings provide a useful space for determining the textual similarity of preprints, which enables us to extend this work beyond word frequencies.
Examining articles with particularly close proximity in this space reveals unannotated preprint-publication pairs that earlier analyses could not consider.
In this space a preprint's nearest neighbors are also more likely than distant articles to share an eventual publishing venue with the preprint itself.
We provide a webserver that will displays neighboring journals and articles for any preprint on _bioRxiv_ or _medRxiv_, which can help authors identify similar papers or suitable journals.
Our linguistic analysis, the first of the bioRxiv corpus, reveals the impact of the life sciences publishing process, introduces a method to identify matching preprint-published article pairs, demonstrates that the text content of preprints is related to their eventual publication venue, and provides a more complete picture of the fraction of preprints that are eventually published.


## Materials and Methods

### Corpora Examined

#### BioRxiv Corpus

BioRxiv [@doi:10.1101/833400] is a repository for life sciences preprints.
We downloaded an xml snapshot of this repository on February 3, 2020 from bioRxiv's Amazon S3 bucket [@url:https://www.biorxiv.org/tdm].
This snapshot contained the full text and image content of 98,023 preprints.
Preprints on bioRxiv are versioned, and in our snapshot 26,905 out of 98,023 contained more than one version.
When preprints had multiple versions, we used the latest one unless otherwise noted.
Authors submitting preprints to _bioRxiv_ select one of twenty-nine different categories.
Researchers also select an article type, which can be a new result, confirmatory finding, or contradictory finding.
Some preprints in this snapshot were withdrawn from bioRxiv: when this happens their content is replaced with the reason for withdrawal. 
As there were very few withdrawn preprints, we did not treat these as a special case.

#### PubMed Central Open Access Corpus

PubMed Central (PMC) [@doi:10.1073/pnas.98.2.381] is a repository that contains free-to-read articles.
PMC articles can be closed access ones from research funded by the United States National Institutes of Health (NIH) appearing after an embargo period or those published under Gold Open Access [@doi:10.1007/s12471-017-1064-2] publishing schemes.
Paper availability within PMC is largely dependent on the journal's participation level [@url:https://www.ncbi.nlm.nih.gov/pmc/about/submission-methods/].
Individual journals can fully participate in submitting articles to PMC, selectively participate sending only a few papers to PMC, only submit papers according to NIH's public access policy [@url:https://grants.nih.gov/grants/policy/nihgps/html5/section_8/8.2.2_nih_public_access_policy.htm], or not participate at all.
As of September 2019, PMC had 5,725,819 articles available [@url:https://www.ncbi.nlm.nih.gov/pmc/about/intro/].
Out of these 5 million articles, about 3 million were open access and available for text processing systems [@doi:10.1093/bioinformatics/btz070; @doi:10.1093/nar/gkz389].
We downloaded a snapshot of this open access subset on January 31, 2020.
This snapshot contained many types of papers: literature reviews, book reviews, editorials, case reports, research articles and more.
We used only research articles, which aligns with the intended role of _bioRxiv_, and we refer to these articles as the PMCOA Corpus.

#### The New York Times Annotated Corpus

The New York Times Annotated Corpus (NYTAC) is [@raw:sandhaus2008new] is collection of newspaper articles from the New York Times dating from January 1, 1987  to June 19, 2007.
This collection contains over 1.8 million articles where 1.5 million of those articles have undergone manual entity tagged by library scientists [@raw:sandhaus2008new].
We downloaded this collection on August 3rd, 2020 from the Linguistic Data Consortium (see Software and Data Availability section) and used the entire collection for our corpora comparison analysis.

### Comparing Corpora

We compared the bioRxiv, PMCOA, and NYTAC corpora to assess the similarities and differences between them.
We use the NYTAC as an out-group to assess the similarity of two life sciences repositories when compared with non-life sciences text.
The corpora contain both words and non-word symbols (e.g., $\pm$), which we refer to together as tokens to avoid confusion.
We calculated the following statistics for each corpus: the number of documents, the number of sentences, the total number of tokens, the number of stopwords, the average length of a document, the average length of a sentence, the number of negations, the number of coordinating conjunctions, the number of pronouns and the number of past tense verbs.
Next, we used spaCy's "en_core_web_sm" model [@raw:spacy2] (version 2.2.3) to preprocess all corpora and filtered out 326 spaCy-provided stopwords.  

Following cleaning, we calculated the frequency of every token across all corpora.
Because many tokens were unique to one set or the other and observed at low frequency, we used the union of the top 100 most frequent tokens from each pair of corpora to compare them.
We generated a contingency table for each token in this union and calculated the odds ratio and 95% confidence interval [@url:https://www.ncbi.nlm.nih.gov/books/NBK431098/].
We measured corpus similarity by calculating the KL divergence across all three corpora, which focuses on token distribution differences as opposed to token-level differences.

### Constructing a Document Representation for Life Sciences Text

We sought to build a model that would capture the linguistic similarity of articles.
Word2vec is a suite of neural networks designed to model linguistic features of words based on their appearance in text.
These models are trained to either predict a word based on its sentence context as a continuous bag of words (CBOW) or predict the context based on a given word in a skipgram model [@arxiv:1301.3781].
Through these prediction tasks the networks learn latent features that can be used for downstream tasks such as identifying similar words.
We used gensim [@raw:rehurek_lrec] (version 3.8.1) to train a word2vec continuous bag of words (CBOW) [@arxiv:1301.3781] model over the _bioRxiv_ corpus.
Our neural network architecture had 300 hidden nodes, and we trained this model for 20 epochs.
We set a fixed random seed and used gensim's default settings for all other hyperparameters.
Following training, we generated a document vector for every article within _bioRxiv_ and PubMed Central.
We calculated the document vector by taking the average of every token present within a given article [@arxiv:1405.4053].
Words absent from the word2vec model were ignored.

### Visualizing and Characterizing Preprint Representations

We sought to visualize the landscape of preprints and determine the extent to which their representation as document vectors corresponded to author-supplied document labels.
We used principal component analysis (PCA) [@doi:10.1111/1467-9868.00196] to project _bioRxiv_ document vectors into a low dimensional space.
We trained this model using the scikit-learn [@raw:scikit-learn] implementation of a randomized solver [@arxiv:0909.4061] with a random seed of 100, output of 50 principal components (PCs), and default settings for all other hyperparameters.
After fitting, each preprint has a score for each PC.
To visualize the tokens associated with each PC, we calculated the cosine similarity of each PC to all tokens in our word2vec model's vocabulary.
We report the top 100 positive and negative scoring tokens in the form of word clouds, where the size of each word corresponds to the magnitude of similarity and color represents positive (orange) or negative (blue) association.

### Discovering Unannotated Preprint-Publication Relationships

The _bioRxiv_ maintainers have automated procedures to link preprints to peer reviewed versions and many journals require authors to update preprints with a link to the published version.
However, this automation is largely based on exact matching of certain attributes, and authors can forget to establish a link after publication.
Authors can change the title between a preprint and published version (e.g., [@doi:10.1101/376665] and [@doi:10.1242/bio.038232]), which prevents _bioRxiv_ from automatically establishing a link.
If the authors do not report the publication to _bioRxiv_, the preprint and the published version are treated as distinct entities despite representing the same underlying research.
We recognized that close proximity in the embedding space could reveal preprint to published version links that were missed by existing automated processes.
First, we used CrossRef [@doi:10.1629/uksg.233] to identify bioRxiv preprints that were linked to a corresponding published article.
We ignored pairs that contained papers not in the PMCOA corpus.
We calculated the distribution of known preprint to published distances by taking the Euclidean distance between the preprint's embedding coordinates and the coordinates of its corresponding published version.
We also calculated a background distribution, which consisted of the distance between each preprint with an annotated publication and a randomly selected article from the same journal.
Next, we calculated distances between preprints without a published version link with PubMed Central articles that weren't matched with a corresponding preprint.
We filtered any potential links with distances that were greater than the minimum value of the background distribution to reduce the curation burden.
Lastly, we binned the remaining pairs based on percentiles from the annotated pairs distribution at the [0,25th percentile), [25th percentile, 50th percentile), [50th percentile, 75th percentile), and [75th percentile, minimum background distance).
We randomly sampled 50 articles from each bin for manual annotation.
We shuffled these four sets to produce a list of 200 potential preprint-published pairs with a randomized order.
We supplied these pairs to two co-authors to manually determine if each link between a preprint and a putative matched version was correct or incorrect.
After the curation process, we encountered eight disagreements between the reviewers.
We supplied the preprint-publication pairs on which reviewers disagreed to a third scientist, who carefully reviewed each case and made a final determination.
We used this curated set to evaluate the extent to which distance in the embedding space revealed true but unannotated links between preprints and their published versions.

### Measuring Time Duration for Preprint Publication Process

We measured the time required for preprints to be published in the peer reviewed literature and compared this time within fields and as a function of the extent to which documents changed between the preprint and publication.
We queried bioRxiv’s application programming interface (API) to obtain the date a preprint was posted onto bioRxiv as well as the date a preprint was accepted for publication.
We calculated the difference between the date at which a preprint was first posted and its publication date to provide a publication interval, and we also recorded the number of preprint versions posted onto bioRxiv.
To measure the amount of textual difference, we calculated the Euclidean distance between the document representation of each preprint and the corresponding published version. 
We performed linear regression to model the relationship between preprint version count and a preprint's time to publication as well as the relationship between document representation distances and a preprint's time to publication.
We visualized results as square bin plots.
We observed a limited number of cases in which authors appeared to post preprints after the date of publication, which results in preprints receiving a negative time difference, as previously reported [@url:https://medium.com/@OmnesRes/the-biorxiv-wall-of-shame-aa3d9cfc4cd7].
We did not remove preprints that had a negative time publication in our linear regression analysis as it was not strictly necessary, but we removed them in our survival curve analysis where they were incompatible with the analytical approach.
In practice, the number with negative publication times and the short lead time between publication and preprint has a minimal impact on results.

Document distances can be difficult to understand, so we sought to contextualize the meaning of a distance unit.
We selected preprints within the Bioinformatics topic area, which was well-represented on bioRxiv.
For preprints submitted to the Bioinformatics topic area, we sampled a pair of preprints and calculated their differences 1000 times and reported the mean.

In addition to contextualizing the document distance, we also wanted to contextualize differences in the time to publication.
We examined time to publication for each topic area using the Kaplan-Meier estimator [@doi:10.4103/0974-7788.76794] on preprints within bioRxiv, treating preprints not yet published as survival.
We generated these curves using the KaplanMeierFitter function from the lifelines [@doi:10.5281/zenodo.4136578] (version 0.25.6) python package.
We reported the half-life of each bioRxiv preprint category.

### Building Journal Venue Classifiers

We hypothesized that preprints would be more likely to be published in journals that contained similar content to the work in question.
To test this hypothesis, we designed an experiment examining document and journal representations.
First, we removed all journals that had fewer than 100 papers in the PMCOA corpus.
A subset of our PMCOA corpus was directly linked to papers in bioRxiv as they had been published as open access articles.
We held out this subset and treated it as a gold standard test set.
We used the remainder of the PMCOA corpus for training and initial evaluation via cross validation.
We imagined a use case of prioritizing relevant journals for preprint authors, and considered a list of ten journal suggestions to be an appropriate number and we considered a prediction to be a true positive if the correct journal appeared within the ten closest neighbors of the query article.

Certain journals publish articles in a focused topic area, while others publish articles that cover many topics.
Likewise, some journals have a publication rate of at most hundreds of papers per year while others publish at a rate of at least ten-thousand papers per year.
Accounting for these characteristics, we designed two approaches - one centered on manuscripts and another centered on journals.

For the manuscript-centric approach, we identified the ten most similar published manuscripts and evaluated where the documents were published.
We embedded each query article into the space defined by the word2vec model as described for preprints.
We selected the ten manuscripts that were nearest by Euclidean distance in the embedding space and returned the journal in which they were published.
The number of journals returned via this method could be less than ten as multiple papers in close proximity to query article may belong to the same journal.
Because this approach was based on paper proximity, we could return the articles that led to each journal being returned.
However, journals that publish more papers are more frequently recommended in this framing.

For the journal-centric approach, we identified the ten most similar journals by constructing a journal representation in the same embedding space.
We computed journal centroids as the average embedding of all published papers in the journal.
We then project a query article into the same space and return the ten closest journal centroids by Euclidean distance.
This technique guaranteed that at least ten distinct journals were returned and prevented journals that publish many papers from being heavily overrepresented.

In both cases, we set the number of neighbors for each model to be 10 and then evaluated both models via 10-fold cross validation.
We evaluated performance of both classifiers on our gold standard test set of published preprints.

### Web Application for Discovering Similar Preprints and Journals

We developed a web application that identifies similar papers and journals for any _bioRxiv_ and _medRxiv_ preprint and that places the preprint into the overall document landscape.
Our web application downloads a pdf version of a preprint hosted on the  _bioRxiv_ or _medRxiv_ server.
We use pdfminer [@url:https://pdfminersix.readthedocs.io/en/latest/index.html] to extract text from the downloaded pdf.
The extracted text is then fed into our word2vec model to construct a document embedding representation.
We pass this representation onto our journal and manuscript search to identify journals based on the ten closest neighbors of individual papers as well as journal centroids.
We implemented this search using sklearn's implementation of k-d trees.
To run cost effectively on AWS, we sharded the k-d trees into four trees.

Accompanying these recommendations, we also provide a neural network derived visualization of our training set and the article's position within it.
We used SAUCIE [@doi:10.1101/2020.03.04.975177], an autoencoder designed to cluster single cell RNA-seq data, to build a two-dimensional embedding space that could be applied to newly generated preprints without retraining, a limitation of other approaches that we explored for visualizing entities expected to lie on a nonlinear manifold.
We trained this model on document embeddings of PMCOA articles that did not contain a matching preprint version.
We used the following parameters to train the model: a hidden size of 2, a learning rate of 0.001, lambda_b of 0, lambda_c of 0.001, and lambda_d of 0.001 for 2000 iterations.
When a user requests a new document, we can then project the document on the pre-trained model to generate a visualization in two-dimensional space.
We illustrate our recommendations as a short list and provide access to our network visualization at [https://greenelab.github.io/annorxiver-journal-recommender/](https://greenelab.github.io/annorxiver-journal-recommender/).

We used the fully trained model to project user-requested _bioRxiv_ preprints onto the generated landscape to enable users to see where their preprint falls along the landscape.


## Results

### Comparing bioRxiv to other corpora

#### bioRxiv Metadata Statistics

<!-- since this is largely recapitulating prior findings, i'd strongly consider moving this to the supplement or arrange it into a small panel of a figure -->
![
Neuroscience and bioinformatics are the two most common author-selected topics for bioRxiv preprints.
](https://raw.githubusercontent.com/greenelab/annorxiver/35d3ea0de3c9c78e3c524736bbaada00928c88fb/biorxiv/exploratory_data_analysis/output/figures/preprint_category.png){#fig:biorxiv_categories}

The preprint landscape is rapidly changing, and the number of bioRxiv preprints in our data download (71,118) was nearly double that of a recent study that reported on a snapshot with 37,648 preprints [@doi:10.7554/eLife.45133].
Because the rate of change is rapid, we first analyzed category data and compared our results with previous findings.
As in previous reports [@doi:10.7554/eLife.45133], neuroscience remains the most common category of preprint followed by bioinformatics (Figure {@fig:biorxiv_categories}).
Microbiology, which was fifth in the most recent report [@doi:10.7554/eLife.45133], has now surpassed evolutionary biology and genomics to move into third.
When authors upload their preprints, they select from three result category types: new results, confirmatory results or contradictory results.
We found that nearly all preprints (97.5%) were categorized as new results, which is consistent with reports on a smaller set [@doi:10.1001/jama.2017.21168].
Taken together, the results suggest that while bioRxiv has experienced dramatic growth, the way in which it is being used appears to have remained consistent in recent years.

#### Global Comparison of bioRxiv and PubMed Central

| Metric                | bioRxiv     | PMC           | NYTAC         |
|-----------------------|-------------|---------------|---------------|
| document count             | 71,118      | 1,977,647     | 1,855,658     |
| sentence count             | 22,195,739  | 480,489,811   | 72,171,037    |
| token count                | 420,969,930 | 8,597,101,167 | 1,218,673,384 |
| stopword count            | 158,429,441 | 3,153,077,263 | 559,391,073   |
| avg. document length        | 312.10      | 242.96        | 38.89         |
| avg. sentence length        | 22.71       | 21.46         | 19.89         |
| negatives                  | 1,148,382   | 24,928,801    | 7,272,401     |
| coordinating conjunctions  | 14,295,736  | 307,082,313   | 38,730,053    |
| coordinating conjunctions% | 3.40%       | 3.57%         | 3.18%         |
| pronouns                   | 4,604,432   | 74,994,125    | 46,712,553    |
| pronouns%                  | 1.09%        | 0.87%         | 3.83%         |
| passives                   | 15,012,441  | 342,407,363   | 19,472,053    |
| passive%                   | 3.57%       | 3.98%         | 1.60%         |

Table: Generated corpora statistics for all corpus used in this project. {#tbl:corpora_stats}

![
BioRxiv is more similar to PubMed Central than to the reference corpus.
This barplot represents the KL divergence between bioRxiv, Pubmed Central and the reference corpus.
The y-axis is the KL divergence metric where lower values indicates similar distributions and vice versa for higher values.
The x-axis represents the number of highly occuring tokens used to calculate the KL divergence.
](https://raw.githubusercontent.com/greenelab/annorxiver/8dbc3f8e248ff3e7958c3420363443f0c61b2cc1/biorxiv/corpora_comparison/output/figures/corpora_kl_divergence.png){#fig:kl_divergence}

![
BioRxiv is more focused on biological discoveries rather than disease treatments and clinical trials.
The plot on the left (A) is a point range plot of the odds ratio with respect to bioRxiv.
Values greater than one indicate a high association with bioRxiv whereas values less than one indicate high association with PubMed Central.
The dotted line provides a breaking point between both categories.
The plot on the right (B) is a bar chart of token frequency appearing in bioRxiv and PMC respectively.
](https://raw.githubusercontent.com/greenelab/annorxiver/8dbc3f8e248ff3e7958c3420363443f0c61b2cc1/biorxiv/corpora_comparison/output/figures/biorxiv_vs_pubmed_central.png){#fig:biorxiv_pmc_global_comparison}

The linguistic style of the bioRxiv corpus differs from the PMC corpus.
We compared and contrasted preprints in bioRxiv, published manuscripts in PMC and newspaper articles from the New York Times (NYTAC) against eachother.
We refer to NYTAC as our reference corpus for the following analysis.
We found that bioRxiv is more similar to PMC than to the reference in terms of token frequencies and corpora statistics (Figure {@fig:kl_divergence} and Table {@tbl:corpora_stats}).
When comparing bioRxiv and PMC to the reference, topic associated and measurement related tokens appear highly enriched (Supplemental Figures {@fig:biorxiv_v_reference} and {@fig:pmc_v_reference}).
Furthermore, we found that tokens such as "neuron", "genome", "RNA" and "network" had a high odds ratio, while tokens such as "patient", "health", $\pm$, and "ml" to have a low odds ratio when comparing bioRxiv to PMC (Figure {@fig:biorxiv_pmc_global_comparison}).
This separation of tokens suggests that articles focused on clinical trials and patient research are more prevalent in PMC than to bioRxiv.
This separation also suggests that bioRxiv has a predominance of preprints focused on neuroscience and bioinformatic topics.
In regard to writing, citation styles diversify from the familiar "et al." form as preprints transition through the publication process.
Additionally, published articles have an increase of typesetting ($\pm$) and measurement symbols ("ml", "age") compared to preprints.

#### Published Preprint Differences

![
Top scoring tokens for preprints are focused on figure citations whereas their published versions are more focused on data availability.
The plot on the left (A) is a point range plot of the odds ratio with respect to preprints.
Values greater than one indicate a high association with preprints while values less than one indicate a high association with published articles.
The dotted line provides a breaking point between both categories.
The plot on the right (B) is a barchart of token frequency appearing in preprints and published versions of preprints respectively.
](https://raw.githubusercontent.com/danich1/annorxiver/9611653a8c8a98a7371915a017b7ffe91cb7d88e/biorxiv/corpora_comparison/output/figures/preprint_published_comparison.png){#fig:pre_published_comp}

A preprint's linguistic style can change once a preprint has undergone the revision process prior to being published.
We quantified this linguistic difference by calculating the odds ratio of tokens appearing in the union of bioRxiv preprints and their published counterparts within PMC.
Tokens with an odds ratio greater than one are mainly centered on paper/figure references and research specific terms (Figure {@fig:pre_published_comp}).
Tokens with an odds ratio of less than one are focused on data availability, and research measurements such as number of cases and controls or significance testing (Figure {@fig:pre_published_comp}).
This enrichment suggests that a key piece in the publication process is verifying that essential parts of research (e.g. data availability, specific measurements) are obvious to future readers within the scientific community.

### Topic Analysis of bioRxiv's Principal Components

![
The top two principal components (PCs) appear to capture the concepts of molecular biology vs quantitative biology (PC1) and neuroscience vs bioinformatics (PC2).
The word clouds (A, C) depict the cosine similarity score between tokens and the first two PCs.
Tokens in orange are most similar to a PC's positive direction while tokens in blue are most similar to a PC's negative direction.
The size of each token indicates the magnitude of the similarity score.
The scatter plot at the top right (B) is a visualization of documents being plotted along the PC directions.
Article categories were hand-picked based on the concepts captured by each PC.
](https://raw.githubusercontent.com/greenelab/annorxiver/35d3ea0de3c9c78e3c524736bbaada00928c88fb/biorxiv/pca_association_experiment/output/pca_plots/figures/pca01_v_pca02_figure.png){#fig:pca_word_cloud_plot}

![
Preprint categories have a diverse spread of quantitative and molecular biology results.
This is box plot shows preprints in each article category projected along the PC1 direction.
Negative values indicate molecular biology concepts, while positive values indicate quantitative biology concepts.
](https://raw.githubusercontent.com/danich1/annorxiver/4e0c90c590dd7958dc424a1b4fefcecccb3c28ad/biorxiv/pca_association_experiment/output/pca_plots/figures/category_box_plot_pc1.svg){#fig:pca1_pointplot}

![
The second PC groups neuroscience related preprint categories and bioinformatics related preprint categories together.
This is box plot shows preprints in each article category projected along the PC2 direction.
Negative values indicate neuroscience concepts, while positive values indicate bioinformatic concepts.
](https://raw.githubusercontent.com/danich1/annorxiver/4e0c90c590dd7958dc424a1b4fefcecccb3c28ad/biorxiv/pca_association_experiment/output/pca_plots/figures/category_box_plot_pc2.svg){#fig:pca2_pointplot}

We explored the primary differences between the full text of bioRxiv preprints by performing principal components analysis on generated document embeddings.
We visualized the correspondence between tokens and the loadings for each principal component (Figure {@fig:pca_word_cloud_plot}A,C).
We also visualized documents projected on selected principal components (Figure {@fig:pca_word_cloud_plot}B).
The first principal component separates bioRxiv preprints that encompass molecular biology results with preprints that contain quantitative biology results (Figure {@fig:pca_word_cloud_plot}C).
This highlights the bisection of biomedical research where majority of results can be categorized under the molecular biology category or the quantitative biology category.
Furthermore, this bisecting trend is evident across individual preprint categories as most categories lie on either side of the first principal component (Figure {@fig:pca1_pointplot}).
We also provide example preprints from the systems biology category to reinforce this concept (Supplemental Table {@tbl:five_pc1_table}).

The second principal component represents the concept of neuroscience vs bioinformatics (Figure {@fig:pca_word_cloud_plot}A).
This principal component suggests that the bulk of preprints within bioRxiv are largely focused around neuroscience and bioinformatic concepts.
This split is evident in Figure {@fig:pca2_pointplot} as enriched categories along this principal component are quite related to neuroscience (negative end) or bioinformatics (positive end).
As with the first principal component we provide example preprints from the systems biology category to reinforce this concept (Supplemental Table {@tbl:five_pc2_table}).
More principal component word clouds can be found on our journal recommender website and within our online repository (see Software and Data Availability).

### Identifying preprints that were not linked with their corresponding publications

![
The distances between preprints and their published version was on average lower than the distance between preprints and a randomly selected published article in the same journal.
This violin plot shows the distribution of distances between both categories.
](https://raw.githubusercontent.com/greenelab/annorxiver/131dcac75d179cb36992af4a31188031800c0958/biorxiv/article_distances/output/figures/biorxiv_article_distance.svg){#fig:article_distance_distributions}

![
The preprint-published pairs with smaller distances have a high change of being a true match.
This bar chart depicts the fraction of true positives over the total number of pairs in each bin.
Each bin contains a total of 200 annotated pairs and is based on the percentiles of the preprint-published distribution.
](https://raw.githubusercontent.com/greenelab/annorxiver/131dcac75d179cb36992af4a31188031800c0958/biorxiv/article_distances/output/figures/distance_bin_accuracy.svg){#fig:article_bin_accuracy}

Many journals require that authors update preprints with links to the published version of their article.
This is accomplished in two ways: _bioRxiv_ may detect the link and automatically add it or authors may notify _bioRxiv_ that their preprint was published.
Sproadically, there are cases where _bioRxiv_ may miss detecting a link or authors may forget to notiy _bioRxiv_ of their recent publcation.
These missing links can make it more difficult to identify the latest version of scientific manuscripts and estimate the fraction of articles that are eventually published [@doi:10.7554/eLife.45133].
We used distance in the document space to identify preprints without an annotated publication but contained very similar content to published articles.
We found that distances between preprints and their corresponding published versions were lower than preprints paired with a random article published in the same journal (Figure {@fig:article_distance_distributions}).
This observation suggests that pairs with low embedding distances could be considered a true match, so we separated articles into quantiles based on the distribution of distances between true preprint-publication pairs.
We curated 50 potential preprint-publication pairs from each of four quantiles and achieved a high inter-rater reliability of 91.7% (Cohen's Kappa [@doi:10.1177/001316446002000104]) for this task.
Out of these two hundred pairs we found that approximately 98% of pairs with an embedding distance in the 0-25th and 25th-50th percentile bins were true matches (Figure {@fig:article_bin_accuracy}).
These two bins contained 1,720 preprint-article pairs, suggesting that many preprints have been published but not previously connected with their published versions.

![
The overall fraction of published preprints is higher than originally estimated in [@doi:10.7554/eLife.45133].
This line plot shows the publication rate of preprints since bioRxiv first started.
The x-axis represents months since bioRxiv started and the y-axis represents the proportion of preprints published.
The light blue line represents the publication rate estimated by Abdill et al. [@doi:10.7554/eLife.45133].
The dark blue line represents the updated publication rate without missing links added while the dark green line is the updated publication rate with missing links added.
The horizontal lines represent the overall proportion of preprints  that are published.
](https://raw.githubusercontent.com/greenelab/annorxiver/8dbc3f8e248ff3e7958c3420363443f0c61b2cc1/biorxiv/article_distances/output/figures/publication_rate.png){#fig:updated_pub_rate}

We overlaid these new annotations onto existing annotations to reassess the overall preprint publication rate reported by Abdill et al. [@doi:10.7554/eLife.45133].
Our filtering criteria were intentionally stringent, so the increased estimate of publication rate amounts to a few percent (Figure {@fig:updated_pub_rate}).
Many of these missed annotations were for preprints posted in the 2017-2018 interval.
Compared to preprints published in 2019 and later, the preprints posted in 2017-2018 are old enough to have a high chance of being published; however, it is interesting that the rate for older preprints was not observed to be higher.

### Factors that affect the time between preprinting and publication

![
On average it takes 16 days for authors to make changes based on peer-review feedback.
This squarebin plot depicts the amount of time it takes a preprint to be published against the distances of a preprint's first version and its corresponding published version.
The x-axis represents the Euclidean distance between document representations, while the y-axis represents the number of days elapsed between a preprint posted on bioRxiv and the time a preprint is published.
The color bar on the right represents the density of each square-bin in this plot where more dense regions have a brighter color compared to their counterparts.
](https://raw.githubusercontent.com/danich1/annorxiver/1efd5a4652c2331212a16dbc844f5323476eb5ff/biorxiv/publication_delay_experiment/output/article_distance_vs_publication_time.svg){#fig:distance_publication_time}

![
It takes on average 51-days for a new version of a preprint to be posted onto bioRxiv.
This squarebin plot depicts the amount of time it takes a preprint to be published against the number of versions posted for a specific preprint.
The x-axis represents the number of different versions a preprint has on bioRxiv, while the y-axis represents the number of days elapsed between a preprint posted on bioRxiv and the time a preprint is published.
The color bar on the right represents the density of each square-bin in this plot where more dense regions have a brighter color compared to their counterparts.
](https://raw.githubusercontent.com/danich1/annorxiver/1efd5a4652c2331212a16dbc844f5323476eb5ff/biorxiv/publication_delay_experiment/output/version_count_vs_publication_time.svg){#fig:version_publication_time}

![
All preprint categories take at least 124 days to publish half of their total respective preprints.
This bargraph depicts the amount of time it takes to get half of the total number of preprints published.
The x-axis reprints days until 50% of preprints are published and the y-axis reprints the different preprint categories.
](https://raw.githubusercontent.com/danich1/annorxiver/1efd5a4652c2331212a16dbc844f5323476eb5ff/biorxiv/time_to_publication/output/preprint_category_halflife.svg){#fig:category_halflife}

Preprints undergo multiple review checkpoints before they are published within a journal [@doi:10.1002/nop2.51].
Oftentimes these checkpoints may result in rejection or revisions requested by a reviewer [@doi:10.1002/nop2.51].
These negative outcomes result in authors may having to drastically edit their preprint, which greatly impedes a preprint reaching a published endpoint.
We sought to quantify the extent to which preprints are stalled when faced with a setback from the peer-review process.
On average preprints are delayed approximately 16 days for every distance unit change (Figure {@#fig:distance_publication_time}).
We found that the average distance between two preprints' in the bioinformatics category was 5.068, which suggests that a single distance unit represents a fifth of a preprint's total text being changed.
Sometimes preprints have to undergo drastic revisions that result in a new version being created.
We found that on average it takes 51 days for authors to construct a new version of a preprint (Figure {@fig:version_publication_time}).
Both the document distance trend and the version number trend confirm that the larger the revision the longer it takes for a preprint to be published.

Preprints in certain categories take less time to publish than others.
we sought to quantify the time each category takes to publish half their total number of preprints.
Every preprint category takes at least 124 days to publish half of their respective preprints (Figure {@fig:category_halflife}).
Categories that took the least amount of time were microbiology and zoology, while scientific communication and education took the most time (Figure {@fig:category_halflife}).
Overall, this suggests that preprints in the microbiology and zoology categories may face less peer-review setbacks compared to other categories.

### Recommending Journals Based on Preprint Representation

![
Both classifiers outperform the randomized baseline when predicting a paper's journal endpoint.
This bargraph shows each model's accuracy in respect to predicting the training and test set.
](https://raw.githubusercontent.com/greenelab/annorxiver/1e98a3d18ba755a87c206931c922231d64dbec2a/pmc/journal_recommendation/output/figures/knn_result.png){#fig:knn_auc}

We sought to identify journals that might publish a preprint based on the text of a paper.
We trained two different classifiers to predict the journal endpoints for already published papers.
One classifier uses the nearest journal centroids, which attempts to capture the topic area of a journal.
The other classifier aims to be more granular and recommends journals based on close proximity of individual papers.
Both classifiers achieved a substantial increase over the random baseline; however, our predictors are not perfect (Figure {@fig:knn_auc}).
This is expected as our dataset contains 2516 different journals where some journals publish papers that cover very specific topic while others publish papers that have a broad set of covered topics.
Our journal centroid classifier performed better than the nearest paper classifier on the held out test set (Figure {@fig:knn_auc}).
Overall, our software provides a starting point for authors to use the text of their preprints to identify potentially suitable publication venues.

![
Here is the workflow of the journal recommender web-app.
Starting with the homescreen users can paste in a _bioRxiv_ or _medRxiv_ DOI, which sends a request to biorxiv or medrxiv (A).
Next our app preprocesses the preprint and returns a listing of the top ten most similar papers (B) and the top ten closest journals to the query (C).
Following the listing, our app manually plots the preprint query onto the Pubmed Central Landscape (D).
Lastly, users can click on a square within the landscape, which will show bin statistics as well as associated word-odd ratios (E).
](images/journal_recommender_workflow.png){#fig:journal_rec_workflow}

We constructed an online app that provides users with journal suggestions based on their preprint content.
Users supply DOIs from _bioRxiv_ or _medRxiv_.
The application then downloads the article, converts the PDF to text, calculates a document embedding score, and returns the ten papers and journals with the most similar representations in the embedding space.
It also embeds the document into the overall PMC landscape for visualization and allows the user to examine principal components and term enrichment for each bin within the landscape (Figure {@fig:journal_rec_workflow}).


## Discussion

We analyzed the language contained used in preprints and examined how it changes through the publication process.
We found that bioRxiv and PubMed Central (PMC) have similar word frequency distributions, which suggests that the overall manner of writing is consistent with the biomedical literature. 
At the token level, those most strongly associated with bioRxiv are related to neuroscience and bioinformatics, which are also fields that have seen high uptake of preprinting [@doi:10.7554/eLife.45133].
We noticed that a multitude of preprints highly associated with the first principal component have restrictive or no copyright license (Supplemental Table {@tbl:five_pc1_table}).
This finding highlights the ongoing problem of restricted access within the scientific community [@doi:10.1038/nature.2017.22161; @url:https://blog.dhimmel.com/biorxiv-licenses/].
We also found that the second principal component for our language embedding differentiated neuroscience and bioinformatics papers.

We examined preprints that were textually similar to published articles and found numerous missing links between preprints and their publsihed counterparts.
This observation led us to find that the life sciences preprint publication rate is higher than previously estimated (Figure {@fig:updated_pub_rate}).
Preprint-publication similarity also predicts journal endpoints with modest performance for already published articles. 
This observation enabled us to provide a web application that allows users to identify the papers and journals that are most similar to a _bioRxiv_ or _medRxiv_ preprint.


## Conclusion and Future Directions

Our linguistic analysis did not reveal substantial changes in the language during the peer-reviewed publishing process.
The tokens most strongly associated with the peer reviewed form, as opposed to the preprint form, were associated with data availability and statistical reporting.
We found that embeddings of preprints and publications could be compared and that distance in this space was meaningful in terms of topic area and the journal of eventual publication.
Being able to identify similar preprints and publications using text content makes it feasible to begin tackling more detailed questions, and our analytical software is all open source to enable others to build upon them.
The analysis of preprints' full text can support new tools that accelerate publishing, integrity checks, and other critically important contributions.


## Software and Data Availability

An online version of this manuscript is available under a Creative Commons Attribution License at [https://greenelab.github.io/annorxiver_manuscript/](https://greenelab.github.io/annorxiver_manuscript/). 
Source for the research portions of this project is dual licensed under the BSD 3-Clause and Creative Commons Public Domain Dedication Licenses at [https://github.com/greenelab/annorxiver](https://github.com/greenelab/annorxiver).
The journal recommendation website can be found at [https://greenelab.github.io/annorxiver-journal-recommender/](https://greenelab.github.io/annorxiver-journal-recommender/) and code for the website is available under a BSD-2-Clause Plus Patent License at [https://github.com/greenelab/annorxiver-journal-recommender](https://github.com/greenelab/annorxiver-journal-recommender).
Full text access for the bioRxiv repository is available at [https://www.biorxiv.org/tdm](https://www.biorxiv.org/tdm).
Access to PubMed Central's Open Access subset is available on NCBI's FTP server at [https://www.ncbi.nlm.nih.gov/pmc/tools/ftp/](https://www.ncbi.nlm.nih.gov/pmc/tools/ftp/).
Access to the New York Times Annotated Corpus (NYTAC) is available upon request with the Linguistic Data Consortium at [https://catalog.ldc.upenn.edu/LDC2008T19](https://catalog.ldc.upenn.edu/LDC2008T19).

## Acknowledgements

The authors would like to thank Ariel Hippen Anderson for evaluating potential missing preprint to published version links.
We also would like to thank Richard Sever and the _bioRxiv_ team for their assistance with access to and support with questions about preprint full text downloaded from _bioRxiv_. 
This work was supported by [Grant GBMF4552](https://www.moore.org/grant-detail?grantId=GBMF4552) from the Gordon Betty Moore Foundation and by NIH T32HG00046, Computational Genomics training grant, from the National Human Genome Reserach Institute (NHGRI).


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>


## Supplemental Figures

![
Topic associated tokens are highly enriched when comparing bioRxiv to the New York Times.
The plot on the left (A) is a point range plot of the odds ratio with respect to bioRxiv.
Values greater than one indicate a high association with bioRxiv whereas values less than one indicate high association with the New York Times.
The dotted line provides a breaking point between both categories.
The plot on the right (B) is a bar chart of token frequency appearing in bioRxiv and New York Times respectively.
](https://raw.githubusercontent.com/greenelab/annorxiver/8dbc3f8e248ff3e7958c3420363443f0c61b2cc1/biorxiv/corpora_comparison/output/figures/biorxiv_vs_reference.png){#fig:biorxiv_v_reference}

![
Typesetting symbols and biologically relevant tokens are highly enriched when comparing PubMed Central (PMC) to the New York Times.
The plot on the left (A) is a point range plot of the odds ratio with respect to PMC.
Values greater than one indicate a high association with PMC whereas values less than one indicate high association with the New York Times.
The dotted line provides a breaking point between both categories.
The plot on the right (B) is a bar chart of token frequency appearing in PMC and New York Times respectively.
](https://raw.githubusercontent.com/greenelab/annorxiver/8dbc3f8e248ff3e7958c3420363443f0c61b2cc1/biorxiv/corpora_comparison/output/figures/pmc_vs_reference.png){#fig:pmc_v_reference}

## Supplemental Tables

| Title [citation]     | PC_1  | License | Figure Thumbnail | Figure Link |
|--------------------------------|-------------------|------------|----------|-------------|
| Conditional Robust Calibration (CRC): a new computational Bayesian methodology for model parameters estimation and identifiability analysis [@doi:10.1101/197400] | 4.700554908074704 | None         | ![](images/paper-thumbnails/pc1/197400_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2017/10/02/197400/F1.large.jpg |
| Machine learning of stochastic gene network phenotypes [@doi:10.1101/825943]                                                                                      | 4.410660604449826 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc1/825943_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/10/31/825943/F5.large.jpg |
| Notions of similarity for computational biology models [@doi:10.1101/044818]                                                                                      | 4.355295926618207 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc1/044818_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2016/03/21/044818/F1.large.jpg |
| GpABC: a Julia package for approximate Bayesian computation with Gaussian process emulation [@doi:10.1101/769299]                                                 | 4.351517618262304 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc1/769299_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/09/18/769299/F1.large.jpg |
| SBpipe: a collection of pipelines for automating repetitive simulation and analysis tasks [@doi:10.1101/107250]                                                   | 4.321847854182741 |  CC-BY-NC-ND |  ![](images/paper-thumbnails/pc1/107250_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2017/02/09/107250/F1.large.jpg |
| | | | | |
| Spatiotemporal proteomics uncovers cathepsin-dependent host cell death during bacterial infection [@doi:10.1101/455048]                                           | -4.263964235099807 |  CC-BY-ND   | ![](images/paper-thumbnails/pc1/455048_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2018/11/07/455048/F1.large.jpg |
| Systems analysis by mass cytometry identifies susceptibility of latent HIV-infected T cells to targeting of p38 and mTOR pathways [@doi:10.1101/371922]           | -4.279016673409032 | CC-BY-NC-ND | ![](images/paper-thumbnails/pc1/371922_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2018/07/19/371922/F1.large.jpg |
| NADPH consumption by L-cystine reduction creates a metabolic vulnerability upon glucose deprivation [@doi:10.1101/733162]                                         | -4.592209988884236 | None        | ![](images/paper-thumbnails/pc1/733162_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/08/13/733162/F1.large.jpg |
| Inhibition of Bruton’s tyrosine kinase reduces NF-kB and NLRP3 inflammasome activity preventing insulin resistance and microvascular disease [@doi:10.1101/745943] | -4.736613689905791 | None        |  ![](images/paper-thumbnails/pc1/745943_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/08/28/745943/F1.large.jpg |
| AKT but not MYC promotes reactive oxygen species-mediated cell death in oxidative culture [@doi:10.1101/754572]                                                   | -4.826793742506695 | None        |  ![](images/paper-thumbnails/pc1/754572_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/09/01/754572/F1.large.jpg |

Table: Top and bottom five systems biology preprints projected onto the PC1 direction. These preprints contain quantitative and molecular biology concepts respectively. {#tbl:five_pc1_table}

| Title [citation]   | PC_2  | License  | Figure Thumbnail | Figure Link |
|--------------------------------|--------------|-------------------|----------|----------|
| Pangenome Analysis of Enterobacteria Reveals Richness of Secondary Metabolite Gene Clusters and their Associated Gene Sets [@doi:10.1101/781328]                                                           | 3.5865702659438883 |  CC-BY-ND    | ![](images/paper-thumbnails/pc2/781328_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/09/25/781328/F1.large.jpg |
| QTG-Finder: a machine-learning based algorithm to prioritize causal genes of quantitative trait loci [@doi:10.1101/484204]                                                                                 | 3.470388383023157  | None         |  ![](images/paper-thumbnails/pc2/484204_thumbnail.png)  | https://www.biorxiv.org/content/biorxiv/early/2019/04/29/484204/F1.large.jpg |
| Identification of candidate genes underlying nodulation-specific phenotypes in Medicago truncotula through integration of genome-wide association studies and co-expression networks [@doi:10.1101/392779] | 3.3814906334073953 |  CC-BY-NC-ND |  ![](images/paper-thumbnails/pc2/392779_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2018/08/16/392779/F1.large.jpg |
| Raw sequence to target gene prediction: An integrated inference pipeline for ChIP-seq and RNA-seq datasets [@doi:10.1101/220152]                                                                           | 3.3632576028389742 | None         |  ![](images/paper-thumbnails/pc2/220152_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2017/11/16/220152/F3.large.jpg |
| The y-ome defines the thirty-four percent of Escherichia coli genes that lack experimental evidence of function [@doi:10.1101/328591]                                                                      | 3.28742786641417   | CC-BY        | ![](images/paper-thumbnails/pc2/328591_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2018/12/03/328591/F1.large.jpg |
| | | | | |
| The effects of time-varying temperature on delays in genetic networks [@doi:10.1101/019687]                                                                                                    | -2.7047102478958056 | None          | ![](images/paper-thumbnails/pc2/019687_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2015/09/24/019687/F1.large.jpg |
| An analog to digital converter creates nuclear localization pulses in yeast calcium signaling [@doi:10.1101/357939]                                                                            | -2.775745000260895  | None          | ![](images/paper-thumbnails/pc2/357939_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2018/06/28/357939/F1.large.jpg |
| Nicotinic modulation of hierarchal inhibitory control over prefrontal cortex resting state dynamics: modeling of genetic modification and schizophreniarelated pathology [@doi:10.1101/301051] | -3.047342382798414  | None          | ![](images/paper-thumbnails/pc2/301051_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2018/04/13/301051/F1.large.jpg |
| Electrical propagation of vasodilatory signals in capillary networks [@doi:10.1101/840280]                                                                                                     | -3.107715578793087  |  CC-BY-NC-ND  | ![](images/paper-thumbnails/pc2/840280_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/11/13/840280/F1.large.jpg |
| Dendritic spine geometry and spine apparatus organization govern the spatiotemporal dynamics of calcium [@doi:10.1101/386367]                                                                  | -3.21533499072831   |  CC-BY-NC-ND  | ![](images/paper-thumbnails/pc2/386367_thumbnail.png) | https://www.biorxiv.org/content/biorxiv/early/2019/05/29/386367/F1.large.jpg |

Table: Top and bottom five systems biology preprints projected onto the PC2 direction. These preprints contain bioinformatis and neuroscience concepts respectively. {#tbl:five_pc2_table}

