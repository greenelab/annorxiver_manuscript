---
author-meta:
- David N. Nicholson
- Vincent Rubinetti
- Dongbo Hu
- Marvin Thielk
- Lawrence E. Hunter
- Casey S. Greene
bibliography:
- content/manual-references.json
date-meta: '2021-04-29'
header-includes: '<!--

  Manubot generated metadata rendered from header-includes-template.html.

  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html

  -->

  <meta name="dc.format" content="text/html" />

  <meta name="dc.title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta name="citation_title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta property="og:title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta property="twitter:title" content="Linguistic Analysis of the bioRxiv Preprint Landscape" />

  <meta name="dc.date" content="2021-04-29" />

  <meta name="citation_publication_date" content="2021-04-29" />

  <meta name="dc.language" content="en-US" />

  <meta name="citation_language" content="en-US" />

  <meta name="dc.relation.ispartof" content="Manubot" />

  <meta name="dc.publisher" content="Manubot" />

  <meta name="citation_journal_title" content="Manubot" />

  <meta name="citation_technical_report_institution" content="Manubot" />

  <meta name="citation_author" content="David N. Nicholson" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA" />

  <meta name="citation_author_orcid" content="0000-0003-0002-5761" />

  <meta name="twitter:creator" content="@dnicholson329" />

  <meta name="citation_author" content="Vincent Rubinetti" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA" />

  <meta name="citation_author_orcid" content="None" />

  <meta name="twitter:creator" content="@vincerubinetti" />

  <meta name="citation_author" content="Dongbo Hu" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA" />

  <meta name="citation_author_orcid" content="None" />

  <meta name="twitter:creator" content="@None" />

  <meta name="citation_author" content="Marvin Thielk" />

  <meta name="citation_author_institution" content="Elsevier, Philadelphia PA, USA" />

  <meta name="citation_author_orcid" content="0000-0002-0751-3664" />

  <meta name="twitter:creator" content="@TheNeuralCoder" />

  <meta name="citation_author" content="Lawrence E. Hunter" />

  <meta name="citation_author_institution" content="Center for Computational Pharmacology, University of Colorado School of Medicine, Aurora CO, USA" />

  <meta name="citation_author_orcid" content="0000-0003-1455-3370" />

  <meta name="twitter:creator" content="@ProfLHunter" />

  <meta name="citation_author" content="Casey S. Greene" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA" />

  <meta name="citation_author_institution" content="Department of Biochemistry and Molecular Genetics, University of Colorado School of Medicine, Aurora CO, USA" />

  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />

  <meta name="twitter:creator" content="@greenescientist" />

  <link rel="canonical" href="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta property="og:url" content="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta property="twitter:url" content="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/annorxiver_manuscript/" />

  <meta name="citation_pdf_url" content="https://greenelab.github.io/annorxiver_manuscript/manuscript.pdf" />

  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/annorxiver_manuscript/manuscript.pdf" />

  <link rel="alternate" type="text/html" href="https://greenelab.github.io/annorxiver_manuscript/v/8517aeb7dbf73e85619dffed71b207e804550186/" />

  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/annorxiver_manuscript/v/8517aeb7dbf73e85619dffed71b207e804550186/" />

  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/annorxiver_manuscript/v/8517aeb7dbf73e85619dffed71b207e804550186/manuscript.pdf" />

  <meta property="og:type" content="article" />

  <meta property="twitter:card" content="summary_large_image" />

  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />

  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />

  <meta name="theme-color" content="#ad1457" />

  <!-- end Manubot generated metadata -->'
keywords:
- biorxiv
- preprints
- pubmed-central
- natural-language-processing
- descriptive-linguistics
lang: en-US
manubot-clear-requests-cache: false
manubot-output-bibliography: output/references.json
manubot-output-citekeys: output/citations.tsv
manubot-requests-cache-path: ci/cache/requests-cache
title: Linguistic Analysis of the bioRxiv Preprint Landscape
...






<small><em>
This manuscript
([permalink](https://greenelab.github.io/annorxiver_manuscript/v/8517aeb7dbf73e85619dffed71b207e804550186/))
was automatically generated
from [greenelab/annorxiver_manuscript@8517aeb](https://github.com/greenelab/annorxiver_manuscript/tree/8517aeb7dbf73e85619dffed71b207e804550186)
on April 29, 2021.
</em></small>

## Authors



+ **David N. Nicholson**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-0002-5761](https://orcid.org/0000-0003-0002-5761)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [danich1](https://github.com/danich1)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [dnicholson329](https://twitter.com/dnicholson329)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA
     · Funded by The Gordon and Betty Moore Foundation (GBMF4552); The National Institutes of Health (T32 HG000046)
  </small>

+ **Vincent Rubinetti**<br>
    · ![GitHub icon](images/github.svg){.inline_icon}
    [vincerubinetti](https://github.com/vincerubinetti)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [vincerubinetti](https://twitter.com/vincerubinetti)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA
     · Funded by The Gordon and Betty Moore Foundation (GBMF4552); The National Institutes of Health (T32 HG010067)
  </small>

+ **Dongbo Hu**<br>
    · ![GitHub icon](images/github.svg){.inline_icon}
    [dongbohu](https://github.com/dongbohu)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA
     · Funded by The Gordon and Betty Moore Foundation (GBMF4552); The National Institutes of Health (T32 HG010067)
  </small>

+ **Marvin Thielk**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0002-0751-3664](https://orcid.org/0000-0002-0751-3664)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [MarvinT](https://github.com/MarvinT)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [TheNeuralCoder](https://twitter.com/TheNeuralCoder)<br>
  <small>
     Elsevier, Philadelphia PA, USA
  </small>

+ **Lawrence E. Hunter**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-1455-3370](https://orcid.org/0000-0003-1455-3370)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [LEHunter](https://github.com/LEHunter)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [ProfLHunter](https://twitter.com/ProfLHunter)<br>
  <small>
     Center for Computational Pharmacology, University of Colorado School of Medicine, Aurora CO, USA
     · Funded by The Gordon and Betty Moore Foundation (GBMF4552)
  </small>

+ **Casey S. Greene**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0001-8713-9213](https://orcid.org/0000-0001-8713-9213)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [cgreene](https://github.com/cgreene)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [greenescientist](https://twitter.com/greenescientist)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine University of Pennsylvania, Philadelphia PA, USA; Department of Biochemistry and Molecular Genetics, University of Colorado School of Medicine, Aurora CO, USA
     · Funded by The Gordon and Betty Moore Foundation (GBMF4552); The National Institutes of Health (T32 HG010067)
  </small>



## Abstract {.page_break_before}

Preprints allow researchers to make their findings available to the scientific community before they have undergone peer review.
Studies on preprints within bioRxiv have been largely focused on article metadata and how often these preprints are downloaded, cited, published, and discussed online.
A missing element that has yet to be examined is the language contained within the bioRxiv preprint repository.
We sought to compare and contrast linguistic features within bioRxiv preprints to published biomedical text as a whole as this is an excellent opportunity to examine how peer review changes these documents.
The most prevalent features that changed appear to be associated with typesetting and mentions of supplementary sections or additional files.
In addition to text comparison, we created document embeddings derived from a preprint-trained word2vec model.
We found that these embeddings are able to parse out different scientific approaches and concepts, link unannotated preprint-peer reviewed article pairs, and identify journals that publish linguistically similar papers to a given preprint.
We also used these embeddings to examine factors associated with the time elapsed between the posting of a first preprint and the appearance of a peer reviewed publication.
We found that preprints with more versions posted and more textual changes took longer to publish.
Lastly, we constructed a web application (https://greenelab.github.io/preprint-similarity-search/) that allows users to identify which journals and articles that are most linguistically similar to a bioRxiv or medRxiv preprint as well as observe where the preprint would be positioned within a published article landscape. 


## Introduction

The dissemination of research findings is key to science.
Initially, much of this communication happened orally [@doi:10.1021/ci00050a001].
During the 17th century, the predominant form of communication shifted to personal letters that were shared from one scientist to another [@doi:10.1021/ci00050a001].
Scientific journals didn't become a predominant mode of communication until the 19th and 20th centuries when the first journal was created [@doi:10.1021/ci00050a001; @smith2006trouble; @doi:10.1300/J123v41n01_04].
Although scientific journals became the primary method of communication, they added high maintenance costs and long publication times to scientific discourse [@smith2006trouble; @doi:10.1300/J123v41n01_04].
Some scientists’ solution to these issues has been to also communicate through preprints, which are scholarly works that have yet to undergo peer review process [@doi:10.1177/0192623318767322; @doi:10.1371/journal.pbio.2003995].

Preprints are commonly hosted on online repositories, where users have open and easy access to these works.
Notable repositories include arXiv [@doi:10.1108/14666180010345564], bioRxiv [@doi:10.1101/833400] and medRxiv [@url:https://www.medrxiv.org/]; however, there are over 60 different repositories available [@url:https://scholarlykitchen.sspnet.org/2019/10/16/the-second-wave-of-preprint-servers-how-can-publishers-keep-afloat/].
The burgeoning uptake of preprints in life sciences has been examined through research focused on metadata from the bioRxiv repository.
For example, life science preprints are being posted at an increasing rate  [@doi:10.1371/journal.pbio.3000269].
Furthermore, these preprints are being rapidly shared on social media, routinely downloaded, and cited [@doi:10.1371/journal.pone.0047523].
Certain preprint categories are read and shared by both scientists and non-scientists alike [@doi:10.1101/2020.03.06.981589].
About two-thirds to three-quarters of preprints are eventually published [@doi:10.7554/eLife.45133; @doi:10.1002/pra2.175] and life science articles that have a corresponding preprint version are cited and discussed more often than articles without them [@doi:10.1162/qss_a_00043; @doi:10.7554/eLife.52646; @doi:10.12688/f1000research.19619.2].
Preprints take an average of 160 days to be published in the peer-reviewed literature [@doi:10.2139/ssrn.3455146], and those with multiple versions take longer to publish[@doi:10.2139/ssrn.3455146].

The rapid uptake of preprints in the life sciences also poses challenges. 
Preprint repositories receive a growing number of submissions [@doi:10.1371/journal.pgen.1008565].
Linking preprints with their published counterparts is a key part of maintaining consistency of scholarly discourse but is challenging to perform manually [@doi:10.1038/530265a; @doi:10.7554/eLife.52646; @doi:10.1007/s11192-021-03900-7].
Errors and omissions in linkage result in missing links and consequently erroneous metadata.
Furthermore, repositories based on standard publishing tools are not designed to show how textual content of preprints is altered due to the peer review process [@doi:10.1371/journal.pgen.1008565].
Certain scientists have expressed concern that they could be scooped by competitors by making results available before publication [@doi:10.1371/journal.pgen.1008565; @doi:10.1371/journal.pbio.3000151].
Preprint repositories by definition do not perform in-depth peer review, which can result in posted preprints containing inconsistent results or conclusions [@doi:10.12688/f1000research.19619.2; @doi:10.1007/s10393-018-1352-3; @doi:10.1038/530265a; @doi:10.1016/j.bpj.2016.06.035]; however, an analysis of preprints posted at the beginning of 2020 revealed that most underwent minor changes as they were published [@doi:10.1101/2021.02.20.432090].
Despite a growing emphasis on using the study of preprints to examine the publishing process in the life sciences, how these findings relate to the text of all documents in bioRxiv has yet to be examined.

Textual analysis uses linguistic, statistical and machine learning techniques to analyze and extract information from text [@doi:10.1111/1475-679X.12123]. 
For instance, scientists analyzed linguistic similarities and differences of biomedical corpora [@doi:10.1186/1471-2105-10-183;10.1186/1471-2105-9-S3-S6; @pmc:PMC442180].
Scientists have provided the community with a number of tools that aide future text mining systems [@doi:10.1093/bib/bbs084; @doi:10.1093/nar/gkz389; @doi:10.1186/s12859-017-1775-9] as well as advice on how to train and test future text processing systems [@doi:10.1186/1471-2105-11-492; @doi:10.1186/1471-2105-13-207; @doi:10.1186/s12859-019-2604-0].
Here, we use textual analysis to examine the bioRxiv repository, placing a particular emphasis on understanding the extent to which full-text analysis can address hypotheses derived from the analysis of metadata alone.

To understand how preprints relate to the traditional publishing ecosystem, we examine the linguistic similarities and differences between preprints and peer-reviewed text and observe how linguistic features change during the peer review and publishing process.
We hypothesize that preprints and biomedical text are quite similar, especially when controlling for the differential uptake of preprints across fields.
Furthermore, we hypothesize that document embeddings [@arxiv:1301.3781; @arxiv:1405.4053] provide a versatile way to disentangle linguistic features along with serving as a practical medium for improving preprint repository functionality.
We test this hypothesis by producing a linguistic landscape of bioRxiv preprints, detecting preprints that change substantially during publication, and identify journals that publish manuscripts that are linguistically similar to a target preprint.
We encapsulate our findings through a web app that projects a user-selected preprint onto this landscape and suggests journals and articles that are linguistically similar.
Taken together, our work reveals how linguistically similar and dissimilar preprints are to peer-reviewed text, quantifies linguistic changes that occur during the peer review process, and highlights the feasibility of document embeddings with respect to preprint repository functionality and peer review's effect on publication time.


## Materials and Methods

### Corpora Examined

Text analytics is generally comparative in nature, so we selected three relevant text corpora for analysis: The BioRxiv corpus, which is the target of the investigation; the PubMedCentral Open Access corpus, which represents the peer-reviewed biomedical literature; and the New York Times Annotated Corpus, which is used a representative of general English text.

#### BioRxiv Corpus

BioRxiv [@doi:10.1101/833400] is a repository for life sciences preprints.
We downloaded an XML snapshot of this repository on February 3, 2020, from bioRxiv's Amazon S3 bucket [@url:https://www.biorxiv.org/tdm].
This snapshot contained the full text and image content of 98,023 preprints.
Preprints on bioRxiv are versioned, and in our snapshot 26,905 out of 98,023 contained more than one version.
When preprints had multiple versions, we used the latest one unless otherwise noted.
Authors submitting preprints to bioRxiv can select one of twenty-nine different categories as well as tag the type of article: a new result, confirmatory finding, or contradictory finding.
A few preprints in this snapshot were later withdrawn from bioRxiv; when this happens their content is replaced with the reason for withdrawal.
As there were very few withdrawn preprints, we did not treat these as a special case.

#### PubMed Central Open Access Corpus

PubMed Central (PMC) is a digital archive for the United States National Institute of Health's Library of Medicine (NIH/NLM) that contains full text biomedical and life science articles [@doi:10.1073/pnas.98.2.381].
Paper availability within PMC is largely dependent on the journal's participation level [@url:https://www.ncbi.nlm.nih.gov/pmc/about/submission-methods/].
PMC articles can be closed access ones from research funded by the NIH appearing after an embargo period or be published under Gold Open Access [@doi:10.1007/s12471-017-1064-2] publishing schemes.
Individual journals have the option to fully participate in submitting articles to PMC, selectively participate sending only a few papers to PMC, only submit papers according to NIH's public access policy [@url:https://grants.nih.gov/grants/policy/nihgps/html5/section_8/8.2.2_nih_public_access_policy.htm], or not participate at all.
As of September 2019, PMC had 5,725,819 articles available [@url:https://www.ncbi.nlm.nih.gov/pmc/about/intro/].
Out of these 5 million articles, about 3 million were open access (PMCOA) and available for text processing systems [@doi:10.1093/bioinformatics/btz070; @doi:10.1093/nar/gkz389].
PMC also contains a resource that holds author manuscripts that have already passed the peer review process [@url:https://www.ncbi.nlm.nih.gov/pmc/about/authorms/].
Since these manuscripts have already been peer-reviewed, we excluded them from our analysis as the scope of our work is focused on examining the beginning and end of a preprint's life cycle.
We downloaded a snapshot of the PMCOA corpus on January 31, 2020.
This snapshot contained many types of articles: literature reviews, book reviews, editorials, case reports, research articles, and more.
We used only research articles, which aligns with the intended role of bioRxiv, and we refer to these articles as the PMCOA corpus.

#### The New York Times Annotated Corpus

The New York Times Annotated Corpus (NYTAC) is [@sandhaus2008new] is a collection of newspaper articles from the New York Times dating from January 1, 1987, to June 19, 2007.
This collection contains over 1.8 million articles where 1.5 million of those articles have undergone manual entity tagged by library scientists [@sandhaus2008new].
We downloaded this collection on August 3rd, 2020 from the Linguistic Data Consortium (see Software and Data Availability section) and used the entire collection as a negative control for our corpora comparison analysis.

### Mapping bioRxiv preprints to their published counterparts

We used CrossRef [@doi:10.1629/uksg.233] to identify bioRxiv preprints that were linked to a corresponding published article.
We accessed CrossRef on July 7th, 2020, and were able to successfully link 23,271 preprints to their published counterparts.
Out of those 23,271 preprint-published pairs only 17,952 pairs had a published version present within the PMCOA corpus. 
For our analyses that involved published links, we only focused on this subset of preprints-published pairs.

### Comparing Corpora

We compared the bioRxiv, PMCOA, and NYTAC corpora to assess the similarities and differences between them.
We used the NYTAC corpus as a negative control to assess the similarity between two life sciences repositories when compared with non-life sciences text.
All corpora contain both words and non-word entities (e.g., numbers or symbols like $\pm$), which we refer to together as tokens to avoid confusion.
We calculated the following characteristic metrics for each corpus: the number of documents, the number of sentences, the total number of tokens, the number of stopwords, the average length of a document, the average length of a sentence, the number of negations, the number of coordinating conjunctions, the number of pronouns and the number of past tense verbs.
Spacy is a lightweight and easy-to-use python package designed to preprocess and filter text [@spacy2].
We used spaCy's "en_core_web_sm" model [@spacy2] (version 2.2.3) to preprocess all corpora and filter out 326 spaCy-provided stopwords.

Following that cleaning process, we calculated the frequency of every token across all corpora.
Because many tokens were unique to one set or the other and observed at low frequency, we focused on the union of the top 0.05% (~100) most frequently occurring tokens within each corpus.
For each token in this union, we generated a contingency table and calculated the odds ratio along with the 95% confidence interval [@url:https://www.ncbi.nlm.nih.gov/books/NBK431098/].
Along with token enrichment analysis, we measured corpora similarity by calculating the Kullback–Leibler (KL) divergence across all corpora.
This metric measures the extent to which two distributions differ.
A low value of KL divergence implicates that two distributions are similar and vice versa for high values.
The optimal number of tokens used to calculate the KL divergence is unknown, so we calculated this metric using a range of the 100 most frequently occurring tokens between two corpora to the 5000 most frequently occurring tokens.

### Constructing a Document Representation for Life Sciences Text

We sought to build a language model to quantify linguistic similarities of biomedical preprint and articles. 
Word2vec is a suite of neural networks designed to model linguistic features of words based on their appearance in the text.
These models are trained to either predict a word based on its sentence context, called a continuous bag of words (CBOW) model, or predict the context based on a given word, called a skipgram model [@arxiv:1301.3781].
Through these prediction tasks, both networks learn latent linguistic features that can be used for downstream tasks such as identifying similar words.
We used gensim [@rehurek_lrec] (version 3.8.1) to train a CBOW  [@arxiv:1301.3781] model over all the main text within each preprint in the bioRxiv corpus.
Determining the best number of dimensions for word embeddings can be a non-trivial task; however, it has been shown that optimal performance is between 100-1000 dimensions [@arxiv:1812.04224].
Based on this finding, we chose to train the CBOW model using 300 hidden nodes, batch size of 10000 words, and for 20 epochs.
We set a fixed random seed and used gensim's default settings for all other hyperparameters.
Once trained, every token present within the CBOW model is associated with a dense vector that represents latent features captured by the network.
We used these word vectors to generate a document representation for every article within the bioRxiv and PMCOA corpora.
For each document, we used spaCy to lemmatize each token and then took the average of every lemmatized token present within the CBOW model as well as the individual document [@arxiv:1405.4053].
Any token present within the document but not in the CBOW model is ignored during this calculation process.

### Visualizing and Characterizing Preprint Representations

We sought to visualize the landscape of preprints and determine the extent to which their representation as document vectors corresponded to author-supplied document labels.
We used principal component analysis (PCA) [@doi:10.1111/1467-9868.00196] to project bioRxiv document vectors into a low-dimensional space.
We trained this model using scikit-learn's [@scikit-learn] implementation of a randomized solver [@arxiv:0909.4061] with a random seed of 100, an output of 50 principal components (PCs), and default settings for all other hyperparameters.
After training the model, every preprint within the bioRxiv corpus is assigned a score for each generated PC.
We sought to uncover concepts captured the generated PCs and used the cosine similarity metric to examine these concepts.
This metric takes two vectors as input and outputs a score between -1 (most dissimilar) and 1 (most similar).
For our use case, we used this metric to score the similarity between all generated PCs and every token within our CBOW model.
We report the top 100 positive and negative scoring tokens in the form of word clouds, where the size of each word corresponds to the magnitude of similarity and color represents positive (orange) or negative (blue) association.

### Discovering Unannotated Preprint-Publication Relationships

The bioRxiv maintainers have automated procedures to link preprints to peer-reviewed versions and many journals require authors to update preprints with a link to the published version.
However, this automation is largely based on the exact matching of certain preprint attributes.
If authors change the title between a preprint and published version (e.g., [@doi:10.1101/376665] and [@doi:10.1242/bio.038232]), then this change will prevent bioRxiv from automatically establishing a link.
Furthermore, if the authors do not report the publication to bioRxiv, the preprint and its corresponding published version are treated as distinct entities despite representing the same underlying research.
We hypothesize that close proximity in the document embedding space could match preprints with their corresponding published version. 
If this finding holds, then we could use this embedding space to fill in links that were missed by existing automated processes.
We used the subset of paper-preprint pairs annotated in CrossRef as described above to calculate the distribution of known preprint to published distances.
This distribution was calculated by taking the Euclidean distance between the preprint's embedding coordinates and the coordinates of its corresponding published version.
We also calculated a background distribution, which consisted of the distance between each preprint with an annotated publication and a randomly selected article from the same journal.
We compared both distributions to determine if there was a difference between both groups as a large difference would indicate that this embedding method can parse preprint-published pairs apart.
Following the comparison of the two distributions, we calculated distances between preprints without a published version link with PMCOA articles that weren't matched with a corresponding preprint.
We filtered any potential links with distances that were greater than the minimum value of the background distribution as we considered these pairs to be true negatives.
Lastly, we binned the remaining pairs based on percentiles from the annotated pairs distribution at the [0,25th percentile), [25th percentile, 50th percentile), [50th percentile, 75th percentile), and [75th percentile, minimum background distance).
We randomly sampled 50 articles from each bin and shuffled these four sets to produce a list of 200 potential preprint-published pairs with a randomized order.
We supplied these pairs to two co-authors to manually determine if each link between a preprint and a putative matched version was correct or incorrect.
After the curation process, we encountered eight disagreements between the reviewers.
We supplied these pairs to a third scientist, who carefully reviewed each case and made a final determination.
Using this curated set, we evaluated the extent to which distance in the embedding space revealed true but unannotated links between preprints and their published versions.

### Measuring Time Duration for Preprint Publication Process

Preprints that are published can take varying amounts of time to be published.
We sought to measure the time required for preprints to be published in the peer-reviewed literature and compared this time measurement across author-selected preprint categories as well as individual preprints.
First, we queried bioRxiv’s application programming interface (API) to obtain the date a preprint was posted onto bioRxiv as well as the date a preprint was accepted for publication.
We measured time elapsed as the difference between the date at which a preprint was first posted on bioRxiv and its publication date.
Along with calculating the amount of time elapsed, we also recorded the number of different preprint versions posted onto bioRxiv.

Using this captured data, we used the Kaplan-Meier estimator [@doi:10.4103/0974-7788.76794] via the KaplanMeierFitter function from the lifelines [@doi:10.5281/zenodo.4136578] (version 0.25.6) python package to calculate the half-life of preprints across all preprint categories within bioRxiv.
We considered survival events as preprints that have yet to be published.
There were a limited number of cases in which authors appeared to post preprints after the date of publication, which results in preprints receiving a negative time difference, as previously reported [@url:https://medium.com/@OmnesRes/the-biorxiv-wall-of-shame-aa3d9cfc4cd7].
We removed these preprints for this analysis as they were incompatible with the rules of the bioRxiv repository.

Following our half-life calculation, we measured the textual difference between preprints and their corresponding published version by calculating the Euclidean distance for their respective embedding representation.
This metric can be difficult to understand within the context of textual differences, so we sought to contextualize the meaning of a distance unit.
We accomplish this by first randomly sampled with replacement a pair of preprints from the Bioinformatics topic area as this was well represented within bioRxiv and contains a diverse set of research articles.
Next, we calculated the distance between two preprints 1000 times and reported the mean.
We repeated the above procedure using every preprint within bioRxiv as a whole.
These two means serve as normalized benchmarks to compare against as distance units are only meaningful when compared to other distances within the same space.
Following our contextualization approach, we performed linear regression to model the relationship between preprint version count with a preprint's time to publication. 
We also performed linear regression to measure the relationship between document embedding distance and a preprint’s time to publication.
For this analysis, we retained preprints with negative time within our linear regression model, and we observed that these preprints had minimal impact on results.
We visualize our version count regression model as a violin plot and our document embeddings regression model as a square bin plot.

### Building Classifiers to Detect Linguistically Similar Journal Venues and Published Articles

Preprints are more likely to be published in journals that contained similar content to the work in question.
We assessed this claim by building classifiers based on document and journal representations.
First, we removed all journals that had fewer than 100 papers in the PMC corpus.
We held our preprint-published subset (see above section 'Mapping bioRxiv preprints to their published counterparts') and treated it as a gold standard test set.
We used the remainder of the PMCOA corpus for training and initial evaluation for our models.

Certain journals publish articles in a focused topic area, while others publish articles that cover many topics.
Likewise, some journals have a publication rate of at most hundreds of papers per year while others publish at a rate of at least ten thousand papers per year.
Accounting for these characteristics, we designed two approaches - one centered on manuscripts and another centered on journals.

For the manuscript-based approach, we identified manuscripts that were most similar to the preprint query and evaluated where these documents were published.
We embedded each query article into the space defined by the word2vec model (see above section ‘Constructing a Document Representation for Life Sciences Text’).
We selected manuscripts close to the query via Euclidean distance in the embedding space.
Once identified we return the journal in which these articles were published.
We also return the articles that led to each journal being reported as this approach allows for journals that frequently publish papers to engulf our results.

We constructed a journal-based approach to accompany the manuscript-based approach to account for the overrepresentation of these high publishing frequency journals.
For this approach, we identified the most similar journals by constructing a journal representation in the same embedding space.
We computed this representation by taking the average embedding of all published papers within a given journal.
We then projected a query article into the same space and returned journals that were close to the query. 

Both models were constructed using the scikit-learn k-Nearest Neighbors implementation [@arXiv:1201.0490] with the number of neighbors set to 10 as this is an appropriate number for our use case.
We consider a prediction to be a true positive if the correct journal appears within our reported list of neighbors and evaluate our performance using 10-fold cross-validation on the training set along with test set evaluation.

### Web Application for Discovering Similar Preprints and Journals

We developed a web application that places any bioRxiv or medRxiv preprint into the overall document landscape and identifies similar papers and journals.
The application downloads a pdf version of any preprint hosted on the bioRxiv or medRxiv server uses PyMuPDF [@url:https://pymupdf.readthedocs.io/en/latest/intro.html] to extract text from the downloaded pdf and feeds the extracted text into our CBOW model to construct a document embedding representation.
We pass this representation onto our journal and manuscript search to identify journals based on the ten closest neighbors of individual papers as well as journal centroids.
We implemented this search using the scikit-learn implementation of k-d trees.
To run it more cost-effectively in a cloud computing environment with limited available memory, we sharded the k-d trees into four trees.

To illustrate the local publication landscape, the app provides a visualization of the article’s position within our training data.
We used SAUCIE [@doi:10.1101/2020.03.04.975177], an autoencoder designed to cluster single-cell RNA-seq data, to build a two-dimensional embedding space that could be applied to newly generated preprints without retraining, a limitation of other approaches that we explored for visualizing entities expected to lie on a nonlinear manifold.
We trained this model on document embeddings of PMC articles that did not contain a matching preprint version.
We used the following parameters to train the model: a hidden size of 2, a learning rate of 0.001, lambda_b of 0, lambda_c of 0.001, and lambda_d of 0.001 for 5000 iterations.
When a user requests a new document, we can then project that document onto our generated two-dimensional space; thereby, allowing the user to see where their preprint falls along the landscape.
We illustrate our recommendations as a shortlist and provide access to our network visualization at our website (see Software and Data Availability).

### Analysis of the Preprints in Motion Collection

Our manuscript describes the large-scale analysis of bioRxiv.
Concurrent with our work, another set of authors performed a detailed curation and analysis of a subset of bioRxiv [@doi:10.1101/2021.02.20.432090] that was focused on preprints posted during the initial stages of the COVID-19 pandemic.
The curated analysis was designed to examine preprints at a time of increased readership [@doi:10.1101/2020.05.22.111294] and includes certain preprints posted from January 1st, 2020 to April 30th, 2020 [@doi:10.1101/2021.02.20.432090]. 
We sought to contextualize this subset, which we term "Preprints in Motion" after the title of the preprint [@doi:10.1101/2021.02.20.432090], within our global picture of the bioRxiv preprint landscape.
We extracted all preprints from the set reported in Preprints in Motion [@doi:10.1101/2021.02.20.432090] and retained any entries in the bioRxiv repository.
We manually downloaded the XML version of these preprints and mapped them to their published counterparts as described above. 
We used Pubmed Central's DOI converter [@url:https://www.ncbi.nlm.nih.gov/pmc/pmctopmid/] to map the published article DOIs with their respective PubMed Central IDs.
We retained articles that were included in the PMCOA corpus and performed a token analysis as described to compare these preprints with their published versions.
As above, we generated document embeddings for every obtained preprint and published article.
We projected these preprint embeddings onto our publication landscape to visually observe the dispersion of this subset.
Finally, we performed a time analysis that paralleled our approach for the full set of preprint-publication pairs to examine relationships between linguistic changes and the time to publication.   


## Results

### Comparing bioRxiv to other corpora

#### bioRxiv Metadata Statistics

The preprint landscape is rapidly changing, and the number of bioRxiv preprints in our data download (71,118) was nearly double that of a recent study that reported on a snapshot with 37,648 preprints [@doi:10.7554/eLife.45133].
Because the rate of change is rapid, we first analyzed category data and compared our results with previous findings.
As in previous reports [@doi:10.7554/eLife.45133], neuroscience remains the most common category of preprint followed by bioinformatics (Supplemental Figure {@fig:biorxiv_categories}).
Microbiology, which was fifth in the most recent report [@doi:10.7554/eLife.45133], has now surpassed evolutionary biology and genomics to move into third.
When authors upload their preprints, they select from three result category types: new results, confirmatory results, or contradictory results.
We found that nearly all preprints (97.5%) were categorized as new results, which is consistent with reports on a smaller set [@doi:10.1001/jama.2017.21168].
Taken together, the results suggest that while bioRxiv has experienced dramatic growth, the way in which it is being used appears to have remained consistent in recent years.

#### Global analysis reveals similarities and differences between bioRxiv and PMC

| Metric                | bioRxiv     | PMC           | NYTAC         |
|-----------------------|-------------|---------------|---------------|
| document count             | 71,118      | 1,977,647     | 1,855,658     |
| sentence count             | 22,195,739  | 480,489,811   | 72,171,037    |
| token count                | 420,969,930 | 8,597,101,167 | 1,218,673,384 |
| stopword count            | 158,429,441 | 3,153,077,263 | 559,391,073   |
| avg. document length        | 312.10      | 242.96        | 38.89         |
| avg. sentence length        | 22.71       | 21.46         | 19.89         |
| negatives                  | 1,148,382   | 24,928,801    | 7,272,401     |
| coordinating conjunctions  | 14,295,736  | 307,082,313   | 38,730,053    |
| coordinating conjunctions% | 3.40%       | 3.57%         | 3.18%         |
| pronouns                   | 4,604,432   | 74,994,125    | 46,712,553    |
| pronouns%                  | 1.09%        | 0.87%         | 3.83%         |
| passives                   | 15,012,441  | 342,407,363   | 19,472,053    |
| passive%                   | 3.57%       | 3.98%         | 1.60%         |

Table: Summary statistics for the bioRxiv, PMC, and NYTAC corpora. {#tbl:corpora_stats}

![
**A.** The Kullback–Leibler divergence measures the extent to which the distributions, not specific tokens, differ from each other.
The token distribution of bioRxiv and PMC corpora is more similar than these biomedical corpora are to the NYTAC one.
**B.** The major differences in token frequencies for the corpora appear to be driven by the fields that have had the highest uptake of bioRxiv, as terms from neuroscience and genomics are relatively more abundant in bioRxiv.
We plotted the 95% confidence interval for each reported token.
**C.** Of the tokens that differ between bioRxiv and PMC, the most abundant in bioRxiv are "et" and "al" while the most abundant in PMC is "study."
**D.** The major differences in token frequencies for preprints and their corresponding published version often appear to be associated with typesetting and supplementary or additional materials.
We plotted the 95% confidence interval for each reported token.
**E.** The tokens with the largest absolute differences in abundance appear to be stylistic.
](https://raw.githubusercontent.com/danich1/annorxiver/77e9d6437069bafec7f0291b9a6c09ad50374b58/figure_generation/output/figure_one_panels.svg){#fig:corpora_comparison_panels width="100%"}

Documents within bioRxiv were slightly longer than those within PMCOA, but both were much longer than those from the control (NYTAC) (Table {@tbl:corpora_stats}).
The average sentence length, the fraction of pronouns, and the use of the passive voice were all more similar between bioRxiv and PMC than they were to NYTAC(Table {@tbl:corpora_stats}).
The Kullback–Leibler (KL) divergence of term frequency distributions between bioRxiv and PMCOA were low, especially among the top few hundred tokens (Figure {@fig:corpora_comparison_panels}A).
As more tokens were incorporated the KL divergence started to increase but remained much lower than the biomedical corpora compared against NYTAC.
These findings support our notion that bioRxiv is linguistically similar to the PMCOA repository.

Terms like "neurons" "genome" and "genetic", which are common in genomics and neuroscience, were more common in bioRxiv than PMCOA while others associated with clinical research, such as "clinical" "patients" and "treatment" were more common in PMCOA (Figure {@fig:corpora_comparison_panels}B and {@fig:corpora_comparison_panels}C).
When controlling for the differences in the body of documents to identify textual changes associated with the publication process, we found that tokens such as "et" "al" were enriched for biorxiv while "$\pm$", "–" were enriched for PMCOA (Figure {@fig:corpora_comparison_panels}D and {@fig:corpora_comparison_panels}E).
Furthermore, we found that certain changes appeared to be related to journal styles: "figure" was more common in bioRxiv while "fig" was relatively more common in PMCOA.
Other changes appeared to be associated with an increasing reference to content external to the manuscript itself: the tokens "supplementary", "additional" and "file" were all more common in PMCOA than bioRxiv suggesting that journals are not simply replacing one token with another but that there are more mentions of such content after peer review.

Taken together these results suggest that the structure of the text within preprints on bioRxiv are similar to published articles within PMCOA.
The differences in uptake across fields are supported not only by differences in authors' categorization of their articles but also in the text of the articles themselves.
At the level of individual manuscripts, the terms that change the most appear to be associated with typesetting, journal style, and an increasing reliance on additional materials after peer review.

### Document embeddings derived from bioRxiv reveal fields and subfields

![
**A.** Principal components (PC) analysis of bioRxiv word2vec embeddings groups documents based on author-selected categories.
We visualized documents from key categories on a scatterplot for the first two PCs.
The first PC separated cell biology from informatics-related fields and the second PC separated bioinformatics from neuroscience fields.
**B.** A word cloud visualization of PC1.
Each word cloud depicts the cosine similarity score between tokens and the first PC.
Tokens in orange were most similar to the PC's positive direction while tokens in blue were most similar to the PC's negative direction.
The size of each token indicates the magnitude of the similarity.
**C.** A word cloud visualization of PC2, which separated bioinformatics from neuroscience.
Similar to the first PC, tokens in orange were most similar to the PC's positive direction while tokens in blue were most similar to the PC's negative direction.
The size of each token indicates the magnitude of the similarity.
**D.** Examining PC1 values for each article by category created a continuum from informatics-related fields on the top through cell biology on the bottom.
Certain article categories (neuroscience, genetics) were spread throughout PC1 values.
**E.** Examining PC2 values for each article by category revealed fields like genomics, bioinformatics, and genetics on the top and neuroscience and behavior on the bottom.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_two_panels.svg){#fig:topic_analysis_panels width="100%"}

Document embeddings provide a means to categorize the language of documents in a way that takes into account the similarities between terms [@arxiv:1405.4053; @arxiv:1707.02377; @arxiv:2001.05727].
We found that the first two PCs separated articles from different author-selected categories (Figure {@fig:topic_analysis_panels}A).
Certain neuroscience papers appeared to be more associated with the cellular biology direction of PC1, while others appeared to be more associated with the informatics-related direction Figure {@fig:topic_analysis_panels}A).
This suggests that the concepts captured by PCs were not exclusively related to their field.

Visualizing token-PC similarity revealed tokens associated with certain research approaches (Figures {@fig:topic_analysis_panels}B and {@fig:topic_analysis_panels}C).
Token association of PC1 shows the separation of cell biology and informatics-related fields through tokens: "empirical", "estimates" and "statistics" depicted in orange and "cultured" and "overexpressing" depicted in blue (Figure {@fig:topic_analysis_panels}B).
Association for PC2 shows the separation of bioinformatics and neuroscience via tokens: "genomic", "genome" and "genomes" depicted in orange and "evoked", "stimulus" and "stimulation" depicted in blue (Figure {@fig:topic_analysis_panels}C).

Examining the value for PC1 across all author-selected categories revealed an ordering of fields from cell biology to informatics-related disciplines (Figure {@fig:topic_analysis_panels}D).
These results suggest that a primary driver of the variability within the language used in bioRxiv could be the divide between informatics and cell biology approaches.
A similar analysis for PC2 suggested that neuroscience and bioinformatics present a similar language continuum (Figure {@fig:topic_analysis_panels}E).
This result supports the notion that bioRxiv contains an influx of neuroscience and bioinformatics-related research results. 
For both of the top two PCs, the submitter-selected category of systems biology preprints was near the middle of the distribution and had a relatively large interquartile range when compared with other categories (Figure {@fig:topic_analysis_panels}D and {@fig:topic_analysis_panels}E), suggesting that systems biology is a broader subfield containing both informatics and cellular biology approaches. 

Examining the top five and bottom five preprints within the systems biology field reinforces PC1's dichotomous theme (Table {@tbl:five_pc1_table}).
Preprints with the highest values [@doi:10.1101/197400;@doi:10.1101/825943;@doi:10.1101/044818;@doi:10.1101/769299;@doi:10.1101/107250] included software packages, machine learning analyses, and other computational biology manuscripts, while preprints with the lowest values [@doi:10.1101/455048;@doi:10.1101/371922;@doi:10.1101/733162;@doi:10.1101/745943;@doi:10.1101/754572] were focused on cellular signaling and protein activity.
We provide the rest of our 50 generated PCs in our online repository (see Software and Data Availability).

| Title [citation]     | PC1  | License | Figure Thumbnail |
|--------------------------------|-------------------|------------|----------|
| Conditional Robust Calibration (CRC): a new computational Bayesian methodology for model parameters estimation and identifiability analysis [@doi:10.1101/197400] | 4.522818390064091 | None         | ![](images/paper-thumbnails/pc1/197400_thumbnail.png) | 
| FPtool a software tool to obtain in silico genotype-phenotype signatures and fingerprints based on massive model simulations [@doi:10.1101/266775]                | 4.348956760251298 | CC-BY        | ![](images/paper-thumbnails/pc1/266775_thumbnail.png)               | 
| GpABC: a Julia package for approximate Bayesian computation with Gaussian process emulation [@doi:10.1101/769299]                                                 | 4.259104249060651 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc1/769299_thumbnail.png) | 
| Notions of similarity for computational biology models [@doi:10.1101/044818]                                                                                      | 4.079855550647664 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc1/044818_thumbnail.png) | 
| SBpipe: a collection of pipelines for automating repetitive simulation and analysis tasks [@doi:10.1101/107250]                                                   | 4.022240241143516 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc1/107250_thumbnail.png) | 
| | | | |
| Bromodomain inhibition reveals FGF15/19 as a target of epigenetic regulation and metabolic control [@doi:10.1101/2019.12.11.872887]                                                                                                                                   | -3.4783803547922414 | None     | ![](images/paper-thumbnails/pc1/2019.12.11.872887_thumbnail.png) | 
| Inhibition of Bruton’s tyrosine kinase reduces NF-kB and NLRP3 inflammasome activity preventing insulin resistance and microvascular disease [@doi:10.1101/745943] | -3.6926161167521476 | None     | ![](images/paper-thumbnails/pc1/745943_thumbnail.png)            | 
| Spatiotemporal proteomics uncovers cathepsin-dependent host cell death during bacterial infection [@doi:10.1101/455048]                                            | -3.728443135960558  | CC-BY-ND | ![](images/paper-thumbnails/pc1/455048_thumbnail.png)            | 
| NADPH consumption by L-cystine reduction creates a metabolic vulnerability upon glucose deprivation [@doi:10.1101/733162]                                          | -3.7363965062637288 | None     | ![](images/paper-thumbnails/pc1/733162_thumbnail.png)            | 
| AKT but not MYC promotes reactive oxygen species-mediated cell death in oxidative culture [@doi:10.1101/754572]                                                    | -3.8769231933681176 | None     | ![](images/paper-thumbnails/pc1/754572_thumbnail.png)            | 

Table: PC1 divided the author-selected category of systems biology preprints along an axis from computational to molecular approaches. {#tbl:five_pc1_table}

### Document embedding similarities reveal unannotated preprint-publication pairs

![
**A.** Preprints are closer in document embedding space to their corresponding peer-reviewed publication than they are to random papers published in the same journal.
**B.** Potential preprint-publication pairs that are unannotated but within the 50th percentile of all preprint-publication pairs in the document embedding space are likely to represent true preprint-publication pairs.
We depict the fraction of true positives over the total number of pairs in each bin.
Accuracy is derived from the curation of a randomized list of 200 potential pairs (50 per quantile) performed in duplicate with a third rater used in the case of disagreement.
**C.** Most preprints are eventually published.
We show the publication rate of preprints since bioRxiv first started.
The x-axis represents months since bioRxiv started and the y-axis represents the proportion of preprints published given the month they were posted.
The light blue line represents the publication rate previously estimated by Abdill et al. [@doi:10.7554/eLife.45133].
The dark blue line represents the updated publication rate using only CrossRef-derived annotations, while the dark green line includes annotations derived from our embedding space approach.
The horizontal lines represent the overall proportion of preprints that are were published as of the time of the annotation snapshot.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_three_panels.svg){#fig:preprint_links_panels width="100%"}

Distances between preprints and their corresponding published versions were nearly always lower than preprints paired with a random article published in the same journal (Figure {@fig:preprint_links_panels}A).
This suggests that embedding distances can identify documents with similar textual content. 
Approximately 98% of our 200 pairs with an embedding distance in the 0-25th and 25th-50th percentile bins were scored as true matches (Figure {@fig:preprint_links_panels}B).
These two bins contained 1,542 preprint-article pairs, suggesting that many preprints may have been published but not previously connected with their published versions.
There is a particular enrichment for preprints published but unlinked within the 2017-2018 interval (Figure {@fig:preprint_links_panels}C).
We expected a higher proportion of such preprints before the year 2019 (many of which may not have been published yet); however, observing relatively few missed annotations before 2017 was against our expectations.
There are several possible explanations for this increasing fraction of missed annotations.
As the number of preprints posted on bioRxiv grows, it may be harder for bioRxiv to establish a link between preprints and their published counterparts simply due to the scale of the challenge.
It is possible that the set of authors participating in the preprint ecosystem is changing and that new participants may be less likely to report missed publications to bioRxiv.
Finally, as familiarity with preprinting grows it is possible that authors are posting preprints earlier in the process and that metadata fields that bioRxiv uses to establish a link may be less stable.

### Preprints with more versions or more text changes took longer to publish

![
**A.** Author-selected categories were associated with modest differences in respect to publication half-life.
Author-selected preprint categories are shown on the y-axis, while the x-axis shows the median time-to-publish for each category.
Error bars represent 95% confidence intervals for each median measurement.
**B.** Preprints with more versions were associated with a longer time to publish.
The x-axis shows the number of versions of a preprint that were posted on bioRxiv and the y-axis shows the number of days that elapsed between when the first version of a preprint was posted on bioRxiv and the date at which the peer-reviewed publication appeared.
The density of observations is depicted in the violin plot with an embedded boxplot.
**C.** Preprints with more substantial text changes took longer to be published.
The x-axis shows the Euclidean distance between document representations of the first version of a preprint and its peer-reviewed form.
The y-axis shows the number of days elapsed between when the first version of a preprint is posted on bioRxiv and the time a preprint is published.
The color bar on the right represents the density of each hexbin in this plot where more dense regions are shown in a brighter color.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_four_panels.svg){#fig:publication_delay_panels width="100%"}

The process of peer review includes several steps which take variable amounts of time [@doi:10.1002/nop2.51] and we sought to measure if there is a difference in publication time between author-selected categories of preprints (Figure {@fig:publication_delay_panels}A).
Of the most abundant preprint categories microbiology was the fastest to publish (140 days, (137, 145 days) [95% CI]) and genomics was the slowest (190 days, (185, 195 days) [95% CI]) (Figure {@fig:publication_delay_panels}A).
We did observe category-specific differences; however, these differences were generally modest, suggesting that the peer review process did not differ dramatically between preprint categories. 
One exception was the Scientific Communication and Education category, which took substantially longer to be peer-reviewed and published (373 days, (373, 398 days) [95% CI]).
This hints that there may be differences in the publication or peer review process or culture that apply to preprints in this category.

Examining peer review's effect on individual preprints, we found a positive correlation between preprints with multiple versions and the time elapsed until publication (Figure {@fig:publication_delay_panels}B). 
Each new version adds additional 51 days before a preprint is published.
This time duration seems broadly compatible with the amount of time it would take to receive reviews and revise a manuscript, suggesting that many authors may be updating their preprints in response to peer reviews or other external feedback.
The embedding space allows us to compare preprint and published documents to determine if the level of change that documents undergo relates to the time that it takes them to be published.
Distances in this space are arbitrary and must be compared to reference distances.
We found that the average distance of two randomly selected papers from the bioinformatics category was 4.470, while the average distance of two randomly selected papers from bioRxiv was 5.343.
Preprints with large embedding space distances from their corresponding peer-reviewed publication took longer to publish (Figure {@fig:publication_delay_panels}C): each additional unit of distance corresponded to roughly forty-three additional days.

Overall, our findings support a model where preprints are reviewed multiple times or those that require larger revisions take longer to publish.


### Preprints with similar document embeddings share publication venues

We developed an online application that returns a listing of published papers and journals that are closest to a query preprint in document embedding space.
This application uses two k-nearest neighbor classifiers that achieved better performance than our baseline model (Supplemental Figure {@fig:knn_auc}) to identify these entities.
Users supply our app with digital object identifiers (DOIs) from bioRxiv or medRxiv and the corresponding preprint is downloaded from the repository.
Next, the preprint's PDF is converted to text, and this text is used to construct a document embedding representation.
This representation is supplied to our classifiers to generate a listing of the ten papers and journals with the most similar representations in the embedding space (Figures {@fig:journal_rec_workflow}A,  {@fig:journal_rec_workflow}B and {@fig:journal_rec_workflow}C).
Furthermore, the user-requested preprint's location in this embedding space is then displayed on our interactive map and users can select regions to identify the terms most associated with those regions (Figures {@fig:journal_rec_workflow}D and {@fig:journal_rec_workflow}E).
Users can also explore the terms associated with the top 50 PCs derived from the document embeddings and those PCs vary across the document landscape.

![
The preprint similarity search app workflow allows users to examine where an individual preprint falls in the overall document landscape.
**A.** Starting with the home screen, users can paste in a bioRxiv or medRxiv DOI, which sends a request to bioRxiv or medRxiv.
Next, the app preprocesses the requested preprint and returns a listing of (**B**) the top ten most similar papers and (**C**) the ten closest journals.
**D.** The app also displays the location of the query preprint in PMC.
**E.** Users can select a square within the landscape to examine statistics associated with the square including the top journals by article count in that square and the odds ratio of tokens.
](images/journal_recommender_workflow.png){#fig:journal_rec_workflow width="100%"}

### Contextualizing the Preprints in Motion Collection

![
The Preprints in Motion Collection results are similar to all preprint results, except that their time to publication was independent of the number of preprint versions and amount of linguistic change.
**A.** Tokens that differed included those associated with typesetting and those associated with the nomenclature of the virus that causes COVID-19.
Error bars show 95% confidence intervals for each token.
**B.** Of the tokens that differ between Preprints in Motion and their published counterparts, the most abundant were associated with the nomenclature of the virus.
**C.** The Preprints in Motion fall across the landscape of PMCOA with respect to linguistic properties.
This square bin plot depicts the binning of all published papers within the PMCOA corpus.
High-density regions are depicted in yellow while low-density regions are in dark blue.
Red dots represent the Preprints in Motion Collection.
**D.** The Preprints in Motion were published faster than other bioRxiv preprints and the number of versions was not associated with an increase in time to publication.
The x-axis shows the number of versions of a preprint that were posted on bioRxiv and the y-axis shows the number of days that elapsed between when the first version of a preprint was posted on bioRxiv and the date at which the peer-reviewed publication appeared.
The density of observations is depicted in the violin plot with an embedded boxplot.
The red dots and red regression line represent Preprints in Motion.
**D.** The Preprints in Motion were published faster than other bioRxiv preprints and no dependence between the amount of linguistic change and time to publish was observed.
The x-axis shows the Euclidean distance between document representations of the first version of a preprint and its peer-reviewed form.
The y-axis shows the number of days elapsed between when the first version of a preprint is posted on bioRxiv and the time a preprint is published.
The color bar on the right represents the density of each hexbin in this plot where more dense regions are shown in a brighter color.
The red dots and red regression line represent Preprints in Motion.
](https://raw.githubusercontent.com/danich1/annorxiver/392ae9765362437116efe3250317f41cddbb3232/figure_generation/output/figure_five_panels.svg){#fig:covid_19_preprints width="100%"}

The Preprints in Motion collection included a set of preprints posted during the first four months of 2020.
We examined the extent to which preprints in this set were representative of the patterns that we identified from our analysis of all of bioRxiv.
As with all of bioRxiv, typesetting tokens changed between preprints and their paired publications.
Our token-level analysis identified certain patterns consistent with our findings across bioRxiv (Figure {@fig:covid_19_preprints}A and {@fig:covid_19_preprints}B).
However, in this set we also observe changes likely associated with the fast-moving nature of COVID-19 research: the token "2019-ncov" became less frequently represented while "sars" and "cov-2" became more represented, likely due to a shift in nomenclature from "2019-nCoV" to "SARS-CoV-2".
The Preprints in Motion were not strongly colocalized in the linguistic landscape, suggesting that the collection covers a diverse set of research approaches (Figure {@fig:covid_19_preprints}C).
Preprints in this collection were published faster than the broader set of bioRxiv preprints (Figure {@fig:covid_19_preprints}D and {@fig:covid_19_preprints}E).
The relationship between time to publication and the number of versions (Figure {@fig:covid_19_preprints}D) and the relationship between time to publication and the amount of linguistic change (Figure {@fig:covid_19_preprints}E) were both lost in the Preprints in Motion set.
Taken together, our findings suggest that Preprints in Motion changed during publication in ways that were aligned with changes in the full preprint set but that peer review was accelerated in ways that broke the time dependences observed with the full bioRxiv set.


## Discussion and Conclusions

BioRxiv is a constantly growing repository that contains life science preprints.
The majority of research involving bioRxiv focuses on the metadata of preprints; however, the language contained within these preprints has not previously been systematically examined.
Throughout this work, we sought to analyze the language contained within these preprints and understand how it changes in response to peer review.
Through our global corpora analysis, we found that writing within bioRxiv is consistent with the biomedical literature contained in the PMCOA repository, suggesting that bioRxiv is linguistically similar to PMCOA.
Token-level analyses between bioRxiv and PMCOA suggested that major differences are driven by research fields; e.g., more patient-related research is prevalent in PMCOA than bioRxiv
This observation is expected as preprints focused on medicine are supported by the complementary medRxiv repository [@url:https://www.medrxiv.org/].
Token-level analyses for preprints and their corresponding published version suggest that peer review may focus on data availability and incorporating extra sections for published papers; however, future analyses are needed to ascertain individual token level changes as preprints venture through the publication process.

Document embeddings are a versatile way to examine language contained within preprints, understanding peer review's effect on preprints, and provide extra functionality for preprint repositories.
Examining linguistic variance contained within document embeddings of life science preprints revealed that the largest source of variability was informatics vs cellular biology.
This observation bisects the majority of life science research categories that have integrated preprints within their publication workflow.
Preprints are typically linked with their published articles via bioRxiv manually establishing a link or authors self-reporting that their preprint has been published; however, gaps can occur as preprints change their appearance through multiple versions or authors do not notify bioRxiv. 
Our work suggests that document embeddings can help fill in missing links within bioRxiv.
Furthermore, our analysis reveals that the publication rate for preprints is higher than previously estimated, even though our analysis can only account for papers that are published open access.
Our results raise the lower bound of the total preprint publication fraction; however, the true fraction is necessarily higher.
Future work, especially that which aims to assess the fraction of preprints that are eventually published, should account for the possibility of missed annotations.

Preprints take a variable amount of time to become published, and we examined factors that influence a preprint’s time to publication.
Our half-life analysis on preprint categories revealed that preprints in most bioRxiv categories take similar amounts of time to be published.
A clear exception is the scientific communication and education category, which contained preprints that took much longer to publish.
In respect to individual preprints, each new version adds several weeks to a preprints time to publication, which is roughly aligned with authors making changes after a round of peer review; furthermore, preprints that undergo substantial changes take longer to publish.
Overall these results illustrate that bioRxiv is a practical resource for obtaining insight into the peer-review process.

Lastly, we found that document embeddings were associated with the eventual journal at which the work was published.
We trained two machine learning models to identify which journals publish linguistically similar papers towards a query preprint.
Our models achieved a considerably higher fold change over the baseline model, so we constructed a web application that makes our models available to the public and returns a list of the papers and journals that are linguistically similar to a bioRxiv or medRxiv preprint.


## Software and Data Availability

An online version of this manuscript is available under a Creative Commons Attribution License at [https://greenelab.github.io/annorxiver_manuscript/](https://greenelab.github.io/annorxiver_manuscript/).
Source for the research portions of this project is dual licensed under the BSD 3-Clause and Creative Commons Public Domain Dedication Licenses at [https://github.com/greenelab/annorxiver](https://github.com/greenelab/annorxiver).
The preprint similarity search website can be found at [https://greenelab.github.io/preprint-similarity-search/](https://greenelab.github.io/preprint-similarity-search/), and code for the website is available under a BSD-2-Clause Plus Patent License at [https://github.com/greenelab/preprint-similarity-search](https://github.com/greenelab/preprint-similarity-search).
Full text access for the bioRxiv repository is available at [https://www.biorxiv.org/tdm](https://www.biorxiv.org/tdm).
Access to PubMed Central's Open Access subset is available on NCBI's FTP server at [https://www.ncbi.nlm.nih.gov/pmc/tools/ftp/](https://www.ncbi.nlm.nih.gov/pmc/tools/ftp/).
Access to the New York Times Annotated Corpus (NYTAC) is available upon request with the Linguistic Data Consortium at [https://catalog.ldc.upenn.edu/LDC2008T19](https://catalog.ldc.upenn.edu/LDC2008T19).

## Acknowledgments

The authors would like to thank Ariel Hippen Anderson for evaluating potential missing preprint to published version links.
We also would like to thank Richard Sever and the bioRxiv team for their assistance with access to and support with questions about preprint full text downloaded from bioRxiv.

## Funding

This work was supported by grants from the Gordon Betty Moore Foundation (GBMF4552) and the National Institutes of Health's National Human Genome Research Institute (NHGRI) under awards T32 HG00046 and R01 HG010067.

## Competing Interests

Marvin Thielk receives a salary from Elsevier Inc. where he contributes NLP expertise to health content operations. 
Elsevier did not restrict the results or interpretations that could be published in this manuscript. 
The opinions expressed here do not reflect the official policy or positions of Elsevier Inc.


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>


## Supplemental Figures

![
Neuroscience and bioinformatics are the two most common author-selected topics for bioRxiv preprints.
](https://raw.githubusercontent.com/danich1/annorxiver/e61b10ad5fc0d23db4c6599b460ddd510ae433a5/biorxiv/exploratory_data_analysis/output/figures/preprint_category.png){#fig:biorxiv_categories tag="S1"}

<!--
Commenting this out for now unless we get asked for it. 

![
Topic associated tokens are highly enriched when comparing bioRxiv to the New York Times.
The plot on the left (A) is a point range plot of the odds ratio with respect to bioRxiv.
Values greater than one indicate a high association with bioRxiv whereas values less than one indicate high association with the New York Times.
The dotted line provides a breaking point between both categories.
The plot on the right (B) is a bar chart of token frequency appearing in bioRxiv and New York Times respectively.
](https://raw.githubusercontent.com/greenelab/annorxiver/master/biorxiv/corpora_comparison/output/figures/biorxiv_vs_reference.png){#fig:biorxiv_v_reference tag="S2"}

![
Typesetting symbols and biologically relevant tokens are highly enriched when comparing PubMed Central (PMC) to the New York Times.
The plot on the left (A) is a point range plot of the odds ratio with respect to PMC.
Values greater than one indicate a high association with PMC whereas values less than one indicate high association with the New York Times.
The dotted line provides a breaking point between both categories.
The plot on the right (B) is a bar chart of token frequency appearing in PMC and New York Times respectively.
](https://raw.githubusercontent.com/greenelab/annorxiver/master/biorxiv/corpora_comparison/output/figures/pmc_vs_reference.png){#fig:pmc_v_reference tag="S3"}
-->

![
Both classifiers outperform the randomized baseline when predicting a paper's journal endpoint.
This bargraph shows each model's accuracy in respect to predicting the training and test set.
](https://raw.githubusercontent.com/danich1/annorxiver/be0b818e2fd57af809b52bbbb5647761d170b6f7/pmc/journal_recommendation/output/figures/knn_result.svg){#fig:knn_auc tag="S2" width="100%"}

<!-- 
Commenting this out for now unless we get asked for it.

## Supplemental Tables

| Title [citation]   | PC_2  | License  | Figure Thumbnail |
|--------------------------------|--------------|-------------------|----------|
| Pangenome Analysis of Enterobacteria Reveals Richness of Secondary Metabolite Gene Clusters and their Associated Gene Sets [@doi:10.1101/781328] | 3.2324188285918978 | CC-BY-ND | ![](images/paper-thumbnails/pc2/781328_thumbnail.png)  | 
| The y-ome defines the thirty-four percent of Escherichia coli genes that lack experimental evidence of function [@doi:10.1101/328591]            | 2.9927461425956734 | CC-BY    | ![](images/paper-thumbnails/pc2/328591_thumbnail.png)  | 
| History of rare diseases and their genetic causes - a data driven approach [@doi:10.1101/595819]                                                 | 2.991601530225049  | CC-BY    | ![](images/paper-thumbnails/pc2/595819_thumbnail.png)  | 
| Raw sequence to target gene prediction: An integrated inference pipeline for ChIP-seq and RNA-seq datasets [@doi:10.1101/220152]                 | 2.8891250760798535 | None     | ![](images/paper-thumbnails/pc2/220152_thumbnail.png)  | 
| QTG-Finder: a machine-learning based algorithm to prioritize causal genes of quantitative trait loci [@doi:10.1101/484204]                       | 2.884473743041575  | None     | !![](images/paper-thumbnails/pc2/484204_thumbnail.png) | 
| | | | | |
| The effects of time-varying temperature on delays in genetic networks [@doi:10.1101/019687]                                                                                                    | -2.512047640539022  | None         | ![](images/paper-thumbnails/pc2/019687_thumbnail.png) | 
| Nicotinic modulation of hierarchal inhibitory control over prefrontal cortex resting state dynamics: modeling of genetic modification and schizophreniarelated pathology [@doi:10.1101/301051] | -2.547393499209389  | None         | ![](images/paper-thumbnails/pc2/301051_thumbnail.png) | 
| An analog to digital converter creates nuclear localization pulses in yeast calcium signaling [@doi:10.1101/357939]                                                                            | -2.5561246453120976 | None         | ![](images/paper-thumbnails/pc2/357939_thumbnail.png) | 
| Electrical propagation of vasodilatory signals in capillary networks [@doi:10.1101/840280]                                                                                                     | -2.903422991868243  | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc2/840280_thumbnail.png) | 
| Dendritic spine geometry and spine apparatus organization govern the spatiotemporal dynamics of calcium [@doi:10.1101/386367]                                                                  | -3.1061160163276282 | CC-BY-NC-ND  | ![](images/paper-thumbnails/pc2/386367_thumbnail.png) | 

Table: Top and bottom five systems biology preprints projected onto the PC2 direction. These preprints contain bioinformatis and neuroscience concepts respectively. {#tbl:five_pc2_table}
-->
